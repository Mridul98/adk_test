2025-11-07 02:34:15.0671 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-07 02:34:16.0648 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-07 02:34:16.0648 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-07 02:34:16.0648 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-07 02:34:16.0649 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-07 02:34:16.0649 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-07 02:34:16.0649 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-07 02:34:16.0649 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-07 02:34:16.0649 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-07 02:34:16.0649 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-07 02:34:16.0649 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-07 02:34:16.0649 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-07 02:34:16.0650 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-07 02:34:16.0650 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-07 02:34:16.0650 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-07 02:34:16.0651 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-07 02:34:16.0658 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-07 02:34:16.0658 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-07 02:34:16.0658 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-07 02:34:16.0680 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-07 02:34:16.0682 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-07 02:34:16.0683 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-07 02:34:16.0697 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-07 02:34:16.0699 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-07 02:34:16.0700 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-07 02:34:16.0700 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-07 02:34:16.0701 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-07 02:34:16.0702 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-07 02:34:16.0703 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-07 02:34:16.0703 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-07 02:34:16.0704 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-07 02:34:16.0704 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-07 02:34:16.0713 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-07 02:34:16.0713 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-07 02:34:16.0715 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-07 02:34:16.0715 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-07 02:34:16.0718 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-07 02:34:16.0730 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-07 02:34:16.0730 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-07 02:34:16.0734 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-07 02:34:16.0734 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-07 02:34:16.0739 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-07 02:39:25.0244 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-07 02:42:48.0550 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-07 02:42:48.0551 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-07 02:42:48.0551 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-07 02:42:48.0551 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-07 02:42:48.0551 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-07 02:43:03.0676 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-07 02:43:04.0368 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-07 02:43:04.0368 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-07 02:43:04.0369 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-07 02:43:04.0369 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-07 02:43:04.0369 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-07 02:43:04.0369 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-07 02:43:04.0369 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-07 02:43:04.0369 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-07 02:43:04.0369 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-07 02:43:04.0370 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-07 02:43:04.0370 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-07 02:43:04.0371 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-07 02:43:04.0371 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-07 02:43:04.0371 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-07 02:43:04.0371 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-07 02:43:04.0376 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-07 02:43:04.0377 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-07 02:43:04.0377 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-07 02:43:04.0380 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-07 02:43:04.0383 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-07 02:43:04.0383 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-07 02:43:04.0390 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-07 02:43:04.0392 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-07 02:43:04.0393 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-07 02:43:04.0394 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-07 02:43:04.0395 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-07 02:43:04.0395 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-07 02:43:04.0396 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-07 02:43:04.0397 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-07 02:43:04.0397 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-07 02:43:04.0398 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-07 02:43:04.0403 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-07 02:43:04.0403 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-07 02:43:04.0406 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-07 02:43:04.0406 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-07 02:43:04.0409 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-07 02:43:04.0418 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-07 02:43:04.0418 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-07 02:43:04.0422 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-07 02:43:04.0422 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-07 02:43:04.0427 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-07 02:43:04.0467 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-07 02:45:31.0344 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-07 02:45:31.0344 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-07 02:45:31.0344 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-07 02:45:31.0344 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-07 02:45:31.0345 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-07 02:45:48.0629 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-07 02:45:48.0669 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-07 02:45:48.0670 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-07 02:45:48.0670 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-07 02:45:48.0670 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-07 02:45:48.0670 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-07 02:45:48.0670 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-07 02:45:48.0670 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-07 02:45:48.0671 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-07 02:45:48.0671 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-07 02:45:48.0671 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-07 02:45:48.0671 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-07 02:45:48.0672 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-07 02:45:48.0672 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-07 02:45:48.0672 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-07 02:45:48.0672 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-07 02:45:48.0677 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-07 02:45:48.0677 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-07 02:45:48.0677 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-07 02:45:48.0680 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-07 02:45:48.0682 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-07 02:45:48.0682 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-07 02:45:48.0687 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-07 02:45:48.0689 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-07 02:45:48.0690 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-07 02:45:48.0690 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-07 02:45:48.0691 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-07 02:45:48.0692 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-07 02:45:48.0692 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-07 02:45:48.0693 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-07 02:45:48.0694 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-07 02:45:48.0695 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-07 02:45:48.0699 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-07 02:45:48.0699 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-07 02:45:48.0701 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-07 02:45:48.0702 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-07 02:45:48.0703 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-07 02:45:48.0711 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-07 02:45:48.0711 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-07 02:45:48.0716 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-07 02:45:48.0716 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-07 02:45:48.0720 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-07 02:45:48.0766 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-07 02:51:25.0398 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-07 02:52:10.0873 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-07 02:53:07.0131 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-07 02:53:38.0819 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-07 02:55:16.0605 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-07 02:55:45.0045 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=596.29 seconds
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client_reqrep.py", line 532, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/streams.py", line 672, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1529, in request
    response = await self._client.send(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/usr/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 452, in make_openai_chat_completion_request
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1547, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=596.29 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 280, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=596.29 seconds
2025-11-07 02:55:45.0147 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=596.39 seconds
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client_reqrep.py", line 532, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/streams.py", line 672, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1529, in request
    response = await self._client.send(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/usr/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 452, in make_openai_chat_completion_request
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1547, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=596.39 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 280, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=596.39 seconds
2025-11-07 02:56:41.0139 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-07 02:56:41.0139 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-07 02:56:41.0139 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-07 02:56:58.0512 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-07 02:56:58.0944 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-07 02:56:58.0944 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-07 02:56:58.0944 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-07 02:56:58.0945 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-07 02:56:58.0945 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-07 02:56:58.0945 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-07 02:56:58.0945 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-07 02:56:58.0945 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-07 02:56:58.0945 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-07 02:56:58.0946 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-07 02:56:58.0946 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-07 02:56:58.0947 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-07 02:56:58.0947 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-07 02:56:58.0947 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-07 02:56:58.0947 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-07 02:56:58.0951 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-07 02:56:58.0952 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-07 02:56:58.0952 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-07 02:56:58.0955 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-07 02:56:58.0957 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-07 02:56:58.0957 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-07 02:56:58.0964 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-07 02:56:58.0966 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-07 02:56:58.0967 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-07 02:56:58.0968 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-07 02:56:58.0969 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-07 02:56:58.0969 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-07 02:56:58.0970 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-07 02:56:58.0971 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-07 02:56:58.0971 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-07 02:56:58.0972 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-07 02:56:58.0975 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-07 02:56:58.0975 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-07 02:56:58.0978 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-07 02:56:58.0978 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-07 02:56:58.0980 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-07 02:56:58.0987 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-07 02:56:58.0987 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-07 02:56:58.0991 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-07 02:56:58.0991 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-07 02:56:58.0995 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-07 02:56:59.0036 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-07 02:56:59.0038 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-07 02:56:59.0038 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-07 02:56:59.0039 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-07 02:56:59.0040 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-07 02:56:59.0040 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-07 03:01:03.0784 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-07 03:02:01.0997 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-07 03:03:47.0181 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-07 03:03:47.0197 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/summarize_descriptions
2025-11-07 03:03:47.0197 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 1/122
2025-11-07 03:03:47.0197 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 2/122
2025-11-07 03:03:47.0197 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 3/122
2025-11-07 03:03:47.0197 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 4/122
2025-11-07 03:03:47.0197 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 5/122
2025-11-07 03:03:47.0197 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 6/122
2025-11-07 03:03:47.0197 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 7/122
2025-11-07 03:03:47.0197 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 8/122
2025-11-07 03:03:47.0197 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 9/122
2025-11-07 03:03:47.0198 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 10/122
2025-11-07 03:03:47.0198 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 11/122
2025-11-07 03:03:47.0198 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 12/122
2025-11-07 03:03:47.0198 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 13/122
2025-11-07 03:03:47.0198 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 14/122
2025-11-07 03:03:47.0198 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 15/122
2025-11-07 03:03:47.0198 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 16/122
2025-11-07 03:03:47.0198 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 17/122
2025-11-07 03:03:47.0198 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 18/122
2025-11-07 03:03:47.0198 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 19/122
2025-11-07 03:03:47.0199 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 20/122
2025-11-07 03:03:47.0199 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 21/122
2025-11-07 03:03:47.0199 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 22/122
2025-11-07 03:03:47.0199 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 23/122
2025-11-07 03:03:47.0199 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 24/122
2025-11-07 03:03:47.0199 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 25/122
2025-11-07 03:03:47.0199 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 26/122
2025-11-07 03:03:47.0200 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 27/122
2025-11-07 03:03:47.0200 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 28/122
2025-11-07 03:03:47.0200 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 29/122
2025-11-07 03:03:47.0200 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 30/122
2025-11-07 03:03:47.0200 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 31/122
2025-11-07 03:03:47.0200 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 32/122
2025-11-07 03:03:47.0200 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 33/122
2025-11-07 03:03:47.0200 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 34/122
2025-11-07 03:03:47.0200 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 35/122
2025-11-07 03:03:47.0200 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 36/122
2025-11-07 03:03:47.0200 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 37/122
2025-11-07 03:03:47.0200 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 38/122
2025-11-07 03:03:47.0200 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 39/122
2025-11-07 03:03:47.0200 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 40/122
2025-11-07 03:03:47.0200 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 41/122
2025-11-07 03:03:47.0200 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 42/122
2025-11-07 03:03:47.0200 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 43/122
2025-11-07 03:03:47.0201 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 44/122
2025-11-07 03:03:47.0201 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 45/122
2025-11-07 03:03:47.0201 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 46/122
2025-11-07 03:03:47.0201 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 47/122
2025-11-07 03:03:47.0201 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 48/122
2025-11-07 03:03:47.0201 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 49/122
2025-11-07 03:03:47.0201 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 50/122
2025-11-07 03:03:47.0201 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 51/122
2025-11-07 03:03:54.0715 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 52/122
2025-11-07 03:04:04.0990 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 53/122
2025-11-07 03:04:13.0573 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 54/122
2025-11-07 03:04:22.0567 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 55/122
2025-11-07 03:04:22.0568 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 56/122
2025-11-07 03:04:22.0568 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 57/122
2025-11-07 03:04:22.0568 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 58/122
2025-11-07 03:04:22.0568 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 59/122
2025-11-07 03:04:22.0568 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 60/122
2025-11-07 03:04:22.0568 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 61/122
2025-11-07 03:04:22.0568 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 62/122
2025-11-07 03:04:22.0568 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 63/122
2025-11-07 03:04:22.0568 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 64/122
2025-11-07 03:04:22.0568 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 65/122
2025-11-07 03:04:22.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 66/122
2025-11-07 03:04:22.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 67/122
2025-11-07 03:04:22.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 68/122
2025-11-07 03:04:22.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 69/122
2025-11-07 03:04:22.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 70/122
2025-11-07 03:04:22.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 71/122
2025-11-07 03:04:22.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 72/122
2025-11-07 03:04:22.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 73/122
2025-11-07 03:04:22.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 74/122
2025-11-07 03:04:22.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 75/122
2025-11-07 03:04:22.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 76/122
2025-11-07 03:04:22.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 77/122
2025-11-07 03:04:22.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 78/122
2025-11-07 03:04:22.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 79/122
2025-11-07 03:04:22.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 80/122
2025-11-07 03:04:22.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 81/122
2025-11-07 03:04:22.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 82/122
2025-11-07 03:04:22.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 83/122
2025-11-07 03:04:22.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 84/122
2025-11-07 03:04:22.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 85/122
2025-11-07 03:04:22.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 86/122
2025-11-07 03:04:22.0569 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 87/122
2025-11-07 03:04:22.0570 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 88/122
2025-11-07 03:04:22.0570 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 89/122
2025-11-07 03:04:22.0570 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 90/122
2025-11-07 03:04:22.0570 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 91/122
2025-11-07 03:04:22.0570 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 92/122
2025-11-07 03:04:22.0570 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 93/122
2025-11-07 03:04:22.0570 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 94/122
2025-11-07 03:04:22.0570 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 95/122
2025-11-07 03:04:22.0570 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 96/122
2025-11-07 03:04:22.0570 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 97/122
2025-11-07 03:04:22.0570 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 98/122
2025-11-07 03:04:22.0570 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 99/122
2025-11-07 03:04:22.0570 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 100/122
2025-11-07 03:04:22.0570 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 101/122
2025-11-07 03:04:22.0571 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 102/122
2025-11-07 03:04:22.0571 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 103/122
2025-11-07 03:04:22.0571 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 104/122
2025-11-07 03:04:22.0571 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 105/122
2025-11-07 03:04:22.0571 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 106/122
2025-11-07 03:04:22.0571 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 107/122
2025-11-07 03:04:22.0571 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 108/122
2025-11-07 03:04:22.0571 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 109/122
2025-11-07 03:04:22.0571 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 110/122
2025-11-07 03:04:22.0571 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 111/122
2025-11-07 03:04:22.0571 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 112/122
2025-11-07 03:04:22.0571 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 113/122
2025-11-07 03:04:22.0571 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 114/122
2025-11-07 03:04:22.0571 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 115/122
2025-11-07 03:04:22.0571 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 116/122
2025-11-07 03:04:22.0571 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 117/122
2025-11-07 03:04:22.0571 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 118/122
2025-11-07 03:04:22.0571 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 119/122
2025-11-07 03:04:22.0571 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 120/122
2025-11-07 03:04:22.0571 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 121/122
2025-11-07 03:04:31.0192 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 122/122
2025-11-07 03:04:31.0198 - INFO - graphrag.index.workflows.extract_graph - Workflow completed: extract_graph
2025-11-07 03:04:31.0198 - INFO - graphrag.api.index - Workflow extract_graph completed successfully
2025-11-07 03:04:31.0209 - INFO - graphrag.index.workflows.finalize_graph - Workflow started: finalize_graph
2025-11-07 03:04:31.0209 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-11-07 03:04:31.0211 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-11-07 03:04:31.0226 - INFO - graphrag.index.workflows.finalize_graph - Workflow completed: finalize_graph
2025-11-07 03:04:31.0226 - INFO - graphrag.api.index - Workflow finalize_graph completed successfully
2025-11-07 03:04:31.0236 - INFO - graphrag.index.workflows.extract_covariates - Workflow started: extract_covariates
2025-11-07 03:04:31.0236 - INFO - graphrag.index.workflows.extract_covariates - Workflow completed: extract_covariates
2025-11-07 03:04:31.0236 - INFO - graphrag.api.index - Workflow extract_covariates completed successfully
2025-11-07 03:04:31.0236 - INFO - graphrag.index.workflows.create_communities - Workflow started: create_communities
2025-11-07 03:04:31.0236 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-11-07 03:04:31.0239 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-11-07 03:04:31.0264 - INFO - graphrag.index.workflows.create_communities - Workflow completed: create_communities
2025-11-07 03:04:31.0265 - INFO - graphrag.api.index - Workflow create_communities completed successfully
2025-11-07 03:04:31.0272 - INFO - graphrag.index.workflows.create_final_text_units - Workflow started: create_final_text_units
2025-11-07 03:04:31.0272 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-07 03:04:31.0275 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-11-07 03:04:31.0277 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-11-07 03:04:31.0290 - INFO - graphrag.index.workflows.create_final_text_units - Workflow completed: create_final_text_units
2025-11-07 03:04:31.0290 - INFO - graphrag.api.index - Workflow create_final_text_units completed successfully
2025-11-07 03:04:31.0295 - INFO - graphrag.index.workflows.create_community_reports - Workflow started: create_community_reports
2025-11-07 03:04:31.0295 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-11-07 03:04:31.0297 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-11-07 03:04:31.0299 - INFO - graphrag.utils.storage - reading table from storage: communities.parquet
2025-11-07 03:04:31.0305 - INFO - graphrag.index.operations.summarize_communities.graph_context.context_builder - Number of nodes at level=1 => 26
2025-11-07 03:04:31.0331 - INFO - graphrag.index.operations.summarize_communities.graph_context.context_builder - Number of nodes at level=0 => 50
2025-11-07 03:04:31.0374 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/community_reporting
2025-11-07 03:11:02.0625 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 1/8
2025-11-07 03:11:02.0625 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 2/8
2025-11-07 03:11:02.0625 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 3/8
2025-11-07 03:11:02.0625 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 4/8
2025-11-07 03:11:02.0626 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 5/8
2025-11-07 03:11:02.0626 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 6/8
2025-11-07 03:11:02.0626 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 7/8
2025-11-07 03:11:02.0626 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 8/8
2025-11-07 03:11:21.0462 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-07 03:11:22.0158 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-07 03:11:22.0158 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-07 03:11:22.0159 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-07 03:11:22.0159 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-07 03:11:22.0159 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-07 03:11:22.0159 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-07 03:11:22.0159 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-07 03:11:22.0159 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-07 03:11:22.0159 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-07 03:11:22.0160 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-07 03:11:22.0160 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-07 03:11:22.0161 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-07 03:11:22.0161 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-07 03:11:22.0161 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-07 03:11:22.0161 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-07 03:11:22.0167 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-07 03:11:22.0167 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-07 03:11:22.0167 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-07 03:11:22.0171 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-07 03:11:22.0174 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-07 03:11:22.0175 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-07 03:11:22.0182 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-07 03:11:22.0185 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-07 03:11:22.0187 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-07 03:11:22.0188 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-07 03:11:22.0189 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-07 03:11:22.0190 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-07 03:11:22.0191 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-07 03:11:22.0192 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-07 03:11:22.0193 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-07 03:11:22.0194 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-07 03:11:22.0199 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-07 03:11:22.0199 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-07 03:11:22.0202 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-07 03:11:22.0202 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-07 03:11:22.0205 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-07 03:11:22.0213 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-07 03:11:22.0214 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-07 03:11:22.0218 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-07 03:11:22.0218 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-07 03:11:22.0223 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-07 03:11:22.0239 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-07 03:11:22.0239 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-07 03:11:22.0240 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-07 03:11:22.0241 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-07 03:11:22.0241 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-07 03:11:22.0242 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-07 03:11:22.0243 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-07 03:11:22.0243 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-07 03:11:22.0243 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-07 03:11:22.0254 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/summarize_descriptions
2025-11-07 03:11:22.0254 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 1/122
2025-11-07 03:11:22.0255 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 2/122
2025-11-07 03:11:22.0255 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 3/122
2025-11-07 03:11:22.0255 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 4/122
2025-11-07 03:11:22.0255 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 5/122
2025-11-07 03:11:22.0255 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 6/122
2025-11-07 03:11:22.0255 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 7/122
2025-11-07 03:11:22.0255 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 8/122
2025-11-07 03:11:22.0255 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 9/122
2025-11-07 03:11:22.0255 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 10/122
2025-11-07 03:11:22.0255 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 11/122
2025-11-07 03:11:22.0255 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 12/122
2025-11-07 03:11:22.0255 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 13/122
2025-11-07 03:11:22.0255 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 14/122
2025-11-07 03:11:22.0255 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 15/122
2025-11-07 03:11:22.0255 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 16/122
2025-11-07 03:11:22.0255 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 17/122
2025-11-07 03:11:22.0256 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 18/122
2025-11-07 03:11:22.0256 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 19/122
2025-11-07 03:11:22.0256 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 20/122
2025-11-07 03:11:22.0256 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 21/122
2025-11-07 03:11:22.0256 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 22/122
2025-11-07 03:11:22.0256 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 23/122
2025-11-07 03:11:22.0257 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 24/122
2025-11-07 03:11:22.0257 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 25/122
2025-11-07 03:11:22.0257 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 26/122
2025-11-07 03:11:22.0258 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 27/122
2025-11-07 03:11:22.0258 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 28/122
2025-11-07 03:11:22.0258 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 29/122
2025-11-07 03:11:22.0258 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 30/122
2025-11-07 03:11:22.0258 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 31/122
2025-11-07 03:11:22.0258 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 32/122
2025-11-07 03:11:22.0258 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 33/122
2025-11-07 03:11:22.0258 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 34/122
2025-11-07 03:11:22.0258 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 35/122
2025-11-07 03:11:22.0258 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 36/122
2025-11-07 03:11:22.0258 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 37/122
2025-11-07 03:11:22.0258 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 38/122
2025-11-07 03:11:22.0258 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 39/122
2025-11-07 03:11:22.0258 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 40/122
2025-11-07 03:11:22.0258 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 41/122
2025-11-07 03:11:22.0258 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 42/122
2025-11-07 03:11:22.0258 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 43/122
2025-11-07 03:11:22.0258 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 44/122
2025-11-07 03:11:22.0259 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 45/122
2025-11-07 03:11:22.0259 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 46/122
2025-11-07 03:11:22.0259 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 47/122
2025-11-07 03:11:22.0259 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 48/122
2025-11-07 03:11:22.0259 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 49/122
2025-11-07 03:11:22.0259 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 50/122
2025-11-07 03:11:22.0259 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 51/122
2025-11-07 03:11:22.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 52/122
2025-11-07 03:11:22.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 53/122
2025-11-07 03:11:22.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 54/122
2025-11-07 03:11:22.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 55/122
2025-11-07 03:11:22.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 56/122
2025-11-07 03:11:22.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 57/122
2025-11-07 03:11:22.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 58/122
2025-11-07 03:11:22.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 59/122
2025-11-07 03:11:22.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 60/122
2025-11-07 03:11:22.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 61/122
2025-11-07 03:11:22.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 62/122
2025-11-07 03:11:22.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 63/122
2025-11-07 03:11:22.0263 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 64/122
2025-11-07 03:11:22.0263 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 65/122
2025-11-07 03:11:22.0263 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 66/122
2025-11-07 03:11:22.0263 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 67/122
2025-11-07 03:11:22.0263 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 68/122
2025-11-07 03:11:22.0263 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 69/122
2025-11-07 03:11:22.0263 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 70/122
2025-11-07 03:11:22.0263 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 71/122
2025-11-07 03:11:22.0263 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 72/122
2025-11-07 03:11:22.0263 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 73/122
2025-11-07 03:11:22.0263 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 74/122
2025-11-07 03:11:22.0263 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 75/122
2025-11-07 03:11:22.0263 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 76/122
2025-11-07 03:11:22.0263 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 77/122
2025-11-07 03:11:22.0263 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 78/122
2025-11-07 03:11:22.0263 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 79/122
2025-11-07 03:11:22.0263 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 80/122
2025-11-07 03:11:22.0263 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 81/122
2025-11-07 03:11:22.0263 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 82/122
2025-11-07 03:11:22.0264 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 83/122
2025-11-07 03:11:22.0264 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 84/122
2025-11-07 03:11:22.0264 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 85/122
2025-11-07 03:11:22.0264 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 86/122
2025-11-07 03:11:22.0264 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 87/122
2025-11-07 03:11:22.0264 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 88/122
2025-11-07 03:11:22.0264 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 89/122
2025-11-07 03:11:22.0264 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 90/122
2025-11-07 03:11:22.0264 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 91/122
2025-11-07 03:11:22.0264 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 92/122
2025-11-07 03:11:22.0264 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 93/122
2025-11-07 03:11:22.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 94/122
2025-11-07 03:11:22.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 95/122
2025-11-07 03:11:22.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 96/122
2025-11-07 03:11:22.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 97/122
2025-11-07 03:11:22.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 98/122
2025-11-07 03:11:22.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 99/122
2025-11-07 03:11:22.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 100/122
2025-11-07 03:11:22.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 101/122
2025-11-07 03:11:22.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 102/122
2025-11-07 03:11:22.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 103/122
2025-11-07 03:11:22.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 104/122
2025-11-07 03:11:22.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 105/122
2025-11-07 03:11:22.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 106/122
2025-11-07 03:11:22.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 107/122
2025-11-07 03:11:22.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 108/122
2025-11-07 03:11:22.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 109/122
2025-11-07 03:11:22.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 110/122
2025-11-07 03:11:22.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 111/122
2025-11-07 03:11:22.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 112/122
2025-11-07 03:11:22.0266 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 113/122
2025-11-07 03:11:22.0266 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 114/122
2025-11-07 03:11:22.0266 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 115/122
2025-11-07 03:11:22.0266 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 116/122
2025-11-07 03:11:22.0266 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 117/122
2025-11-07 03:11:22.0266 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 118/122
2025-11-07 03:11:22.0266 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 119/122
2025-11-07 03:11:22.0266 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 120/122
2025-11-07 03:11:22.0266 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 121/122
2025-11-07 03:11:30.0835 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 122/122
2025-11-07 03:11:30.0841 - INFO - graphrag.index.workflows.extract_graph - Workflow completed: extract_graph
2025-11-07 03:11:30.0841 - INFO - graphrag.api.index - Workflow extract_graph completed successfully
2025-11-07 03:11:30.0852 - INFO - graphrag.index.workflows.finalize_graph - Workflow started: finalize_graph
2025-11-07 03:11:30.0852 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-11-07 03:11:30.0854 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-11-07 03:11:30.0870 - INFO - graphrag.index.workflows.finalize_graph - Workflow completed: finalize_graph
2025-11-07 03:11:30.0870 - INFO - graphrag.api.index - Workflow finalize_graph completed successfully
2025-11-07 03:11:30.0880 - INFO - graphrag.index.workflows.extract_covariates - Workflow started: extract_covariates
2025-11-07 03:11:30.0880 - INFO - graphrag.index.workflows.extract_covariates - Workflow completed: extract_covariates
2025-11-07 03:11:30.0880 - INFO - graphrag.api.index - Workflow extract_covariates completed successfully
2025-11-07 03:11:30.0880 - INFO - graphrag.index.workflows.create_communities - Workflow started: create_communities
2025-11-07 03:11:30.0880 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-11-07 03:11:30.0883 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-11-07 03:11:30.0907 - INFO - graphrag.index.workflows.create_communities - Workflow completed: create_communities
2025-11-07 03:11:30.0907 - INFO - graphrag.api.index - Workflow create_communities completed successfully
2025-11-07 03:11:30.0915 - INFO - graphrag.index.workflows.create_final_text_units - Workflow started: create_final_text_units
2025-11-07 03:11:30.0916 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-07 03:11:30.0919 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-11-07 03:11:30.0921 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-11-07 03:11:30.0934 - INFO - graphrag.index.workflows.create_final_text_units - Workflow completed: create_final_text_units
2025-11-07 03:11:30.0934 - INFO - graphrag.api.index - Workflow create_final_text_units completed successfully
2025-11-07 03:11:30.0939 - INFO - graphrag.index.workflows.create_community_reports - Workflow started: create_community_reports
2025-11-07 03:11:30.0940 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-11-07 03:11:30.0942 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-11-07 03:11:30.0945 - INFO - graphrag.utils.storage - reading table from storage: communities.parquet
2025-11-07 03:11:30.0952 - INFO - graphrag.index.operations.summarize_communities.graph_context.context_builder - Number of nodes at level=1 => 26
2025-11-07 03:11:30.0980 - INFO - graphrag.index.operations.summarize_communities.graph_context.context_builder - Number of nodes at level=0 => 50
2025-11-07 03:11:31.0028 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/community_reporting
2025-11-07 03:18:00.0503 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 1/8
2025-11-07 03:21:03.0253 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 2/8
2025-11-07 03:21:29.0340 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 3/8
2025-11-07 03:21:29.0370 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=598.33 seconds
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client_reqrep.py", line 532, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/streams.py", line 672, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1529, in request
    response = await self._client.send(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/usr/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 452, in make_openai_chat_completion_request
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1547, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=598.33 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 280, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=598.33 seconds
2025-11-07 03:21:29.0387 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=598.34 seconds
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client_reqrep.py", line 532, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/streams.py", line 672, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1529, in request
    response = await self._client.send(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/usr/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 452, in make_openai_chat_completion_request
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1547, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=598.34 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 280, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=598.34 seconds
2025-11-07 03:21:29.0467 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=598.43 seconds
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client_reqrep.py", line 532, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/streams.py", line 672, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1529, in request
    response = await self._client.send(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/usr/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 452, in make_openai_chat_completion_request
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1547, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=598.43 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 280, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=598.43 seconds
2025-11-07 03:21:29.0536 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=598.49 seconds
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client_reqrep.py", line 532, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/streams.py", line 672, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1529, in request
    response = await self._client.send(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/usr/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 452, in make_openai_chat_completion_request
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1547, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=598.49 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 280, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=598.49 seconds
2025-11-07 03:21:29.0552 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=598.51 seconds
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client_reqrep.py", line 532, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/streams.py", line 672, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1529, in request
    response = await self._client.send(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/usr/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 452, in make_openai_chat_completion_request
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1547, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=598.51 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 280, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=598.51 seconds
2025-11-07 03:22:19.0188 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 4/8
2025-11-07 03:22:19.0188 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 5/8
2025-11-07 03:22:19.0188 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 6/8
2025-11-07 03:22:19.0188 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 7/8
2025-11-07 03:22:19.0188 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 8/8
2025-11-07 03:22:36.0127 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-07 03:22:36.0799 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-07 03:22:36.0799 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-07 03:22:36.0800 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-07 03:22:36.0800 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-07 03:22:36.0800 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-07 03:22:36.0800 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-07 03:22:36.0800 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-07 03:22:36.0800 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-07 03:22:36.0801 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-07 03:22:36.0801 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-07 03:22:36.0801 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-07 03:22:36.0802 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-07 03:22:36.0802 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-07 03:22:36.0802 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-07 03:22:36.0802 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-07 03:22:36.0807 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-07 03:22:36.0807 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-07 03:22:36.0807 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-07 03:22:36.0810 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-07 03:22:36.0813 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-07 03:22:36.0813 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-07 03:22:36.0820 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-07 03:22:36.0822 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-07 03:22:36.0823 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-07 03:22:36.0823 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-07 03:22:36.0824 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-07 03:22:36.0825 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-07 03:22:36.0825 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-07 03:22:36.0826 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-07 03:22:36.0827 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-07 03:22:36.0828 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-07 03:22:36.0832 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-07 03:22:36.0832 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-07 03:22:36.0834 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-07 03:22:36.0834 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-07 03:22:36.0836 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-07 03:22:36.0844 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-07 03:22:36.0844 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-07 03:22:36.0848 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-07 03:22:36.0848 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-07 03:22:36.0851 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-07 03:22:36.0863 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-07 03:22:36.0864 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-07 03:22:36.0865 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-07 03:22:36.0865 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-07 03:22:36.0865 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-07 03:22:36.0866 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-07 03:22:36.0866 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-07 03:22:36.0867 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-07 03:22:36.0867 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-07 03:22:36.0876 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/summarize_descriptions
2025-11-07 03:22:36.0876 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 1/122
2025-11-07 03:22:36.0876 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 2/122
2025-11-07 03:22:36.0876 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 3/122
2025-11-07 03:22:36.0876 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 4/122
2025-11-07 03:22:36.0876 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 5/122
2025-11-07 03:22:36.0877 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 6/122
2025-11-07 03:22:36.0877 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 7/122
2025-11-07 03:22:36.0877 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 8/122
2025-11-07 03:22:36.0877 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 9/122
2025-11-07 03:22:36.0877 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 10/122
2025-11-07 03:22:36.0877 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 11/122
2025-11-07 03:22:36.0877 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 12/122
2025-11-07 03:22:36.0877 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 13/122
2025-11-07 03:22:36.0877 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 14/122
2025-11-07 03:22:36.0877 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 15/122
2025-11-07 03:22:36.0877 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 16/122
2025-11-07 03:22:36.0877 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 17/122
2025-11-07 03:22:36.0877 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 18/122
2025-11-07 03:22:36.0878 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 19/122
2025-11-07 03:22:36.0878 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 20/122
2025-11-07 03:22:36.0878 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 21/122
2025-11-07 03:22:36.0878 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 22/122
2025-11-07 03:22:36.0878 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 23/122
2025-11-07 03:22:36.0878 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 24/122
2025-11-07 03:22:36.0878 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 25/122
2025-11-07 03:22:36.0878 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 26/122
2025-11-07 03:22:36.0879 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 27/122
2025-11-07 03:22:36.0879 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 28/122
2025-11-07 03:22:36.0879 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 29/122
2025-11-07 03:22:36.0879 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 30/122
2025-11-07 03:22:36.0879 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 31/122
2025-11-07 03:22:36.0879 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 32/122
2025-11-07 03:22:36.0879 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 33/122
2025-11-07 03:22:36.0879 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 34/122
2025-11-07 03:22:36.0879 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 35/122
2025-11-07 03:22:36.0879 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 36/122
2025-11-07 03:22:36.0879 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 37/122
2025-11-07 03:22:36.0879 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 38/122
2025-11-07 03:22:36.0880 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 39/122
2025-11-07 03:22:36.0880 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 40/122
2025-11-07 03:22:36.0880 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 41/122
2025-11-07 03:22:36.0880 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 42/122
2025-11-07 03:22:36.0880 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 43/122
2025-11-07 03:22:36.0880 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 44/122
2025-11-07 03:22:36.0880 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 45/122
2025-11-07 03:22:36.0880 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 46/122
2025-11-07 03:22:36.0880 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 47/122
2025-11-07 03:22:36.0880 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 48/122
2025-11-07 03:22:36.0880 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 49/122
2025-11-07 03:22:36.0880 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 50/122
2025-11-07 03:22:36.0880 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 51/122
2025-11-07 03:22:36.0882 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 52/122
2025-11-07 03:22:36.0882 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 53/122
2025-11-07 03:22:36.0882 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 54/122
2025-11-07 03:22:36.0883 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 55/122
2025-11-07 03:22:36.0883 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 56/122
2025-11-07 03:22:36.0883 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 57/122
2025-11-07 03:22:36.0883 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 58/122
2025-11-07 03:22:36.0883 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 59/122
2025-11-07 03:22:36.0883 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 60/122
2025-11-07 03:22:36.0884 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 61/122
2025-11-07 03:22:36.0884 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 62/122
2025-11-07 03:22:36.0884 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 63/122
2025-11-07 03:22:36.0884 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 64/122
2025-11-07 03:22:36.0884 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 65/122
2025-11-07 03:22:36.0884 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 66/122
2025-11-07 03:22:36.0884 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 67/122
2025-11-07 03:22:36.0884 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 68/122
2025-11-07 03:22:36.0884 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 69/122
2025-11-07 03:22:36.0884 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 70/122
2025-11-07 03:22:36.0884 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 71/122
2025-11-07 03:22:36.0884 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 72/122
2025-11-07 03:22:36.0884 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 73/122
2025-11-07 03:22:36.0884 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 74/122
2025-11-07 03:22:36.0884 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 75/122
2025-11-07 03:22:36.0884 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 76/122
2025-11-07 03:22:36.0884 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 77/122
2025-11-07 03:22:36.0884 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 78/122
2025-11-07 03:22:36.0884 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 79/122
2025-11-07 03:22:36.0884 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 80/122
2025-11-07 03:22:36.0884 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 81/122
2025-11-07 03:22:36.0884 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 82/122
2025-11-07 03:22:36.0884 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 83/122
2025-11-07 03:22:36.0885 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 84/122
2025-11-07 03:22:36.0885 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 85/122
2025-11-07 03:22:36.0885 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 86/122
2025-11-07 03:22:36.0885 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 87/122
2025-11-07 03:22:36.0885 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 88/122
2025-11-07 03:22:36.0885 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 89/122
2025-11-07 03:22:36.0885 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 90/122
2025-11-07 03:22:36.0885 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 91/122
2025-11-07 03:22:36.0885 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 92/122
2025-11-07 03:22:36.0885 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 93/122
2025-11-07 03:22:36.0885 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 94/122
2025-11-07 03:22:36.0885 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 95/122
2025-11-07 03:22:36.0886 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 96/122
2025-11-07 03:22:36.0886 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 97/122
2025-11-07 03:22:36.0886 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 98/122
2025-11-07 03:22:36.0886 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 99/122
2025-11-07 03:22:36.0886 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 100/122
2025-11-07 03:22:36.0886 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 101/122
2025-11-07 03:22:36.0886 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 102/122
2025-11-07 03:22:36.0886 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 103/122
2025-11-07 03:22:36.0886 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 104/122
2025-11-07 03:22:36.0886 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 105/122
2025-11-07 03:22:36.0886 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 106/122
2025-11-07 03:22:36.0886 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 107/122
2025-11-07 03:22:36.0886 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 108/122
2025-11-07 03:22:36.0886 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 109/122
2025-11-07 03:22:36.0886 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 110/122
2025-11-07 03:22:36.0886 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 111/122
2025-11-07 03:22:36.0886 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 112/122
2025-11-07 03:22:36.0886 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 113/122
2025-11-07 03:22:36.0886 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 114/122
2025-11-07 03:22:36.0886 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 115/122
2025-11-07 03:22:36.0886 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 116/122
2025-11-07 03:22:36.0886 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 117/122
2025-11-07 03:22:36.0886 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 118/122
2025-11-07 03:22:36.0887 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 119/122
2025-11-07 03:22:36.0887 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 120/122
2025-11-07 03:22:36.0887 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 121/122
2025-11-07 03:22:36.0887 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 122/122
2025-11-07 03:22:36.0892 - INFO - graphrag.index.workflows.extract_graph - Workflow completed: extract_graph
2025-11-07 03:22:36.0892 - INFO - graphrag.api.index - Workflow extract_graph completed successfully
2025-11-07 03:22:36.0902 - INFO - graphrag.index.workflows.finalize_graph - Workflow started: finalize_graph
2025-11-07 03:22:36.0902 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-11-07 03:22:36.0904 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-11-07 03:22:36.0917 - INFO - graphrag.index.workflows.finalize_graph - Workflow completed: finalize_graph
2025-11-07 03:22:36.0917 - INFO - graphrag.api.index - Workflow finalize_graph completed successfully
2025-11-07 03:22:36.0926 - INFO - graphrag.index.workflows.extract_covariates - Workflow started: extract_covariates
2025-11-07 03:22:36.0926 - INFO - graphrag.index.workflows.extract_covariates - Workflow completed: extract_covariates
2025-11-07 03:22:36.0926 - INFO - graphrag.api.index - Workflow extract_covariates completed successfully
2025-11-07 03:22:36.0926 - INFO - graphrag.index.workflows.create_communities - Workflow started: create_communities
2025-11-07 03:22:36.0926 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-11-07 03:22:36.0929 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-11-07 03:22:36.0952 - INFO - graphrag.index.workflows.create_communities - Workflow completed: create_communities
2025-11-07 03:22:36.0953 - INFO - graphrag.api.index - Workflow create_communities completed successfully
2025-11-07 03:22:36.0959 - INFO - graphrag.index.workflows.create_final_text_units - Workflow started: create_final_text_units
2025-11-07 03:22:36.0959 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-07 03:22:36.0961 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-11-07 03:22:36.0963 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-11-07 03:22:36.0975 - INFO - graphrag.index.workflows.create_final_text_units - Workflow completed: create_final_text_units
2025-11-07 03:22:36.0975 - INFO - graphrag.api.index - Workflow create_final_text_units completed successfully
2025-11-07 03:22:36.0979 - INFO - graphrag.index.workflows.create_community_reports - Workflow started: create_community_reports
2025-11-07 03:22:36.0979 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-11-07 03:22:36.0982 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-11-07 03:22:36.0984 - INFO - graphrag.utils.storage - reading table from storage: communities.parquet
2025-11-07 03:22:36.0990 - INFO - graphrag.index.operations.summarize_communities.graph_context.context_builder - Number of nodes at level=1 => 26
2025-11-07 03:22:37.0015 - INFO - graphrag.index.operations.summarize_communities.graph_context.context_builder - Number of nodes at level=0 => 50
2025-11-07 03:22:37.0062 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/community_reporting
2025-11-07 03:22:37.0102 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 1/8
2025-11-07 03:22:37.0103 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 2/8
2025-11-07 03:22:37.0103 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 3/8
2025-11-07 03:24:41.0285 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 4/8
2025-11-07 03:25:02.0795 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 5/8
2025-11-07 03:25:23.0515 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 6/8
2025-11-07 03:25:44.0993 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 7/8
2025-11-07 03:26:40.0659 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 8/8
2025-11-07 03:29:03.0823 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 1/6
2025-11-07 03:29:34.0282 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 2/6
2025-11-07 03:31:39.0148 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 3/6
2025-11-07 03:31:57.0506 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 4/6
2025-11-07 03:32:20.0557 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 5/6
2025-11-07 03:32:49.0537 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 6/6
2025-11-07 03:32:49.0545 - INFO - graphrag.index.workflows.create_community_reports - Workflow completed: create_community_reports
2025-11-07 03:32:49.0546 - INFO - graphrag.api.index - Workflow create_community_reports completed successfully
2025-11-07 03:32:49.0559 - INFO - graphrag.index.workflows.generate_text_embeddings - Workflow started: generate_text_embeddings
2025-11-07 03:32:49.0560 - INFO - graphrag.index.workflows.generate_text_embeddings - Embedding the following fields: ['entity.description', 'community.full_content', 'text_unit.text']
2025-11-07 03:32:49.0560 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-07 03:32:49.0562 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-11-07 03:32:49.0565 - INFO - graphrag.utils.storage - reading table from storage: community_reports.parquet
2025-11-07 03:32:49.0569 - INFO - graphrag.index.workflows.generate_text_embeddings - Creating embeddings
2025-11-07 03:32:49.0569 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding entity.description: default-entity-description
2025-11-07 03:32:49.0603 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/1 of size 500 to vector store
2025-11-07 03:32:49.0603 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/text_embedding
2025-11-07 03:32:49.0605 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 54 inputs via 54 snippets using 4 batches. max_batch_size=16, batch_max_tokens=8191
2025-11-07 03:32:50.0267 - INFO - graphrag.logger.progress - generate embeddings progress: 1/4
2025-11-07 03:32:50.0380 - INFO - graphrag.logger.progress - generate embeddings progress: 2/4
2025-11-07 03:32:50.0487 - INFO - graphrag.logger.progress - generate embeddings progress: 3/4
2025-11-07 03:32:50.0566 - INFO - graphrag.logger.progress - generate embeddings progress: 4/4
2025-11-07 03:32:50.0762 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
2025-11-07 03:32:50.0763 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/1 of size 500 to vector store
2025-11-07 03:32:50.0768 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 14 inputs via 14 snippets using 2 batches. max_batch_size=16, batch_max_tokens=8191
2025-11-07 03:32:50.0961 - INFO - graphrag.logger.progress - generate embeddings progress: 1/2
2025-11-07 03:32:51.0019 - INFO - graphrag.logger.progress - generate embeddings progress: 2/2
2025-11-07 03:32:51.0031 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
2025-11-07 03:32:51.0031 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/1 of size 500 to vector store
2025-11-07 03:32:51.0034 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 9 inputs via 9 snippets using 1 batches. max_batch_size=16, batch_max_tokens=8191
2025-11-07 03:32:51.0166 - INFO - graphrag.logger.progress - generate embeddings progress: 1/1
2025-11-07 03:32:51.0176 - INFO - graphrag.index.workflows.generate_text_embeddings - Workflow completed: generate_text_embeddings
2025-11-07 03:32:51.0176 - INFO - graphrag.api.index - Workflow generate_text_embeddings completed successfully
2025-11-07 03:32:51.0200 - INFO - graphrag.index.run.run_pipeline - Indexing pipeline complete.
2025-11-07 03:32:51.0202 - INFO - graphrag.cli.index - All workflows completed successfully.
2025-11-15 12:49:16.0207 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-15 12:49:17.0451 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-15 12:49:17.0451 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-15 12:49:17.0452 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-15 12:49:17.0452 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-15 12:49:17.0452 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-15 12:49:17.0452 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-15 12:49:17.0452 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-15 12:49:17.0453 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-15 12:49:17.0453 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-15 12:49:17.0453 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-15 12:49:17.0453 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-15 12:49:17.0454 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-15 12:49:17.0454 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-15 12:49:17.0454 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-15 12:49:17.0455 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-15 12:49:17.0462 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-15 12:49:17.0463 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-15 12:49:17.0463 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-15 12:49:17.0487 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-15 12:49:17.0490 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-15 12:49:17.0490 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 12:49:17.0505 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-15 12:49:17.0508 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-15 12:49:17.0509 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-15 12:49:17.0510 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-15 12:49:17.0510 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-15 12:49:17.0511 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-15 12:49:17.0512 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-15 12:49:17.0513 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-15 12:49:17.0514 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-15 12:49:17.0515 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-15 12:49:17.0523 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-15 12:49:17.0524 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-15 12:49:17.0526 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-15 12:49:17.0526 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 12:49:17.0529 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 12:49:17.0541 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-15 12:49:17.0541 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-15 12:49:17.0545 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-15 12:49:17.0545 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 12:49:17.0551 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-15 12:52:48.0796 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-15 12:56:06.0851 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-15 12:58:18.0867 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.27 seconds
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client_reqrep.py", line 532, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/streams.py", line 672, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1529, in request
    response = await self._client.send(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/usr/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 452, in make_openai_chat_completion_request
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1547, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.27 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 280, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.27 seconds
2025-11-15 12:58:18.0978 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.39 seconds
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client_reqrep.py", line 532, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/streams.py", line 672, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1529, in request
    response = await self._client.send(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/usr/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 452, in make_openai_chat_completion_request
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1547, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.39 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 280, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.39 seconds
2025-11-15 12:58:18.0995 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.41 seconds
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client_reqrep.py", line 532, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/streams.py", line 672, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1529, in request
    response = await self._client.send(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/usr/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 452, in make_openai_chat_completion_request
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1547, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.41 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 280, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.41 seconds
2025-11-15 12:58:19.0048 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.46 seconds
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client_reqrep.py", line 532, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/streams.py", line 672, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1529, in request
    response = await self._client.send(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/usr/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 452, in make_openai_chat_completion_request
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1547, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.46 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 280, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.46 seconds
2025-11-15 12:59:15.0091 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-15 12:59:58.0450 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-15 12:59:58.0451 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-15 12:59:58.0451 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-15 12:59:58.0451 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-15 12:59:58.0451 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-15 12:59:58.0451 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-15 13:00:14.0659 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-15 13:00:15.0364 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-15 13:00:15.0364 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-15 13:00:15.0364 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-15 13:00:15.0365 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-15 13:00:15.0365 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-15 13:00:15.0365 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-15 13:00:15.0365 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-15 13:00:15.0365 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-15 13:00:15.0365 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-15 13:00:15.0366 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-15 13:00:15.0366 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-15 13:00:15.0367 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-15 13:00:15.0367 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-15 13:00:15.0367 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-15 13:00:15.0367 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-15 13:00:15.0373 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-15 13:00:15.0373 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-15 13:00:15.0374 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-15 13:00:15.0378 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-15 13:00:15.0381 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-15 13:00:15.0381 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 13:00:15.0387 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-15 13:00:15.0390 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-15 13:00:15.0393 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-15 13:00:15.0395 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-15 13:00:15.0396 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-15 13:00:15.0398 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-15 13:00:15.0399 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-15 13:00:15.0401 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-15 13:00:15.0402 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-15 13:00:15.0403 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-15 13:00:15.0408 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-15 13:00:15.0408 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-15 13:00:15.0410 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-15 13:00:15.0411 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 13:00:15.0415 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 13:00:15.0424 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-15 13:00:15.0424 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-15 13:00:15.0428 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-15 13:00:15.0428 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 13:00:15.0432 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-15 13:00:15.0480 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-15 13:00:15.0481 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-15 13:00:15.0482 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-15 13:09:16.0872 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.39 seconds
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client_reqrep.py", line 532, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/streams.py", line 672, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1529, in request
    response = await self._client.send(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/usr/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 452, in make_openai_chat_completion_request
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1547, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.39 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 280, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.39 seconds
2025-11-15 13:09:16.0957 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.48 seconds
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client_reqrep.py", line 532, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/streams.py", line 672, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1529, in request
    response = await self._client.send(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/usr/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 452, in make_openai_chat_completion_request
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1547, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.48 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 280, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.48 seconds
2025-11-15 13:09:51.0909 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.27 seconds
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client_reqrep.py", line 532, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/streams.py", line 672, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1529, in request
    response = await self._client.send(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/usr/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 452, in make_openai_chat_completion_request
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1547, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.27 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 280, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.27 seconds
2025-11-15 13:10:43.0179 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.75 seconds
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client_reqrep.py", line 532, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/streams.py", line 672, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1529, in request
    response = await self._client.send(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/usr/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 452, in make_openai_chat_completion_request
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1547, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.75 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 280, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.75 seconds
2025-11-15 13:10:51.0653 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-15 13:10:51.0654 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-15 13:10:51.0654 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-15 13:10:51.0654 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-15 13:10:51.0654 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-15 13:10:51.0654 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-15 13:11:07.0426 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-15 13:11:08.0183 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-15 13:11:08.0183 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-15 13:11:08.0184 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-15 13:11:08.0184 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-15 13:11:08.0184 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-15 13:11:08.0184 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-15 13:11:08.0184 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-15 13:11:08.0184 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-15 13:11:08.0184 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-15 13:11:08.0185 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-15 13:11:08.0185 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-15 13:11:08.0186 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-15 13:11:08.0186 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-15 13:11:08.0186 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-15 13:11:08.0186 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-15 13:11:08.0192 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-15 13:11:08.0193 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-15 13:11:08.0193 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-15 13:11:08.0197 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-15 13:11:08.0200 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-15 13:11:08.0200 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 13:11:08.0207 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-15 13:11:08.0210 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-15 13:11:08.0211 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-15 13:11:08.0211 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-15 13:11:08.0212 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-15 13:11:08.0213 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-15 13:11:08.0214 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-15 13:11:08.0215 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-15 13:11:08.0216 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-15 13:11:08.0217 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-15 13:11:08.0221 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-15 13:11:08.0221 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-15 13:11:08.0224 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-15 13:11:08.0224 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 13:11:08.0227 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 13:11:08.0235 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-15 13:11:08.0236 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-15 13:11:08.0240 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-15 13:11:08.0240 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 13:11:08.0244 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-15 13:11:08.0295 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-15 13:11:08.0296 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-15 13:11:08.0297 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-15 13:11:43.0665 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-15 13:12:55.0774 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-15 13:13:34.0276 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-15 13:14:54.0549 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-15 13:15:36.0072 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-15 13:16:28.0025 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-15 13:16:28.0027 - ERROR - graphrag.index.run.run_pipeline - error running workflow extract_graph
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/run/run_pipeline.py", line 121, in _run_pipeline
    result = await workflow_function(config, context)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/workflows/extract_graph.py", line 50, in run_workflow
    entities, relationships, raw_entities, raw_relationships = await extract_graph(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/workflows/extract_graph.py", line 95, in extract_graph
    extracted_entities, extracted_relationships = await extractor(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/operations/extract_graph/extract_graph.py", line 79, in extract_graph
    entities = _merge_entities(entity_dfs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/operations/extract_graph/extract_graph.py", line 103, in _merge_entities
    all_entities.groupby(["title", "type"], sort=False)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/pandas/core/frame.py", line 9210, in groupby
    return DataFrameGroupBy(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/pandas/core/groupby/groupby.py", line 1331, in __init__
    grouper, exclusions, obj = get_grouper(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/pandas/core/groupby/grouper.py", line 1043, in get_grouper
    raise KeyError(gpr)
KeyError: 'title'
2025-11-15 13:16:28.0032 - ERROR - graphrag.api.index - Workflow extract_graph completed with errors
2025-11-15 13:16:28.0033 - ERROR - graphrag.cli.index - Errors occurred during the pipeline run, see logs for more details.
2025-11-15 13:27:39.0830 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-15 13:27:40.0828 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-15 13:27:40.0828 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-15 13:27:40.0828 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-15 13:27:40.0829 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-15 13:27:40.0829 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-15 13:27:40.0829 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-15 13:27:40.0829 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-15 13:27:40.0829 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-15 13:27:40.0829 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-15 13:27:40.0830 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-15 13:27:40.0830 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-15 13:27:40.0831 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-15 13:27:40.0831 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-15 13:27:40.0831 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-15 13:27:40.0832 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-15 13:27:40.0840 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-15 13:27:40.0840 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-15 13:27:40.0840 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-15 13:27:40.0864 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-15 13:27:40.0867 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-15 13:27:40.0867 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 13:27:40.0882 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-15 13:27:40.0884 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-15 13:27:40.0885 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-15 13:27:40.0886 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-15 13:27:40.0887 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-15 13:27:40.0888 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-15 13:27:40.0889 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-15 13:27:40.0890 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-15 13:27:40.0890 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-15 13:27:40.0891 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-15 13:27:40.0900 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-15 13:27:40.0900 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-15 13:27:40.0903 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-15 13:27:40.0903 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 13:27:40.0907 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 13:27:40.0920 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-15 13:27:40.0920 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-15 13:27:40.0924 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-15 13:27:40.0924 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 13:27:40.0931 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-15 13:27:40.0945 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-15 13:27:40.0945 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-15 13:27:40.0946 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-15 13:27:40.0946 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-15 13:27:40.0947 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-15 13:27:40.0947 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-15 13:27:40.0947 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-15 13:27:40.0947 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-15 13:27:40.0948 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-15 13:27:40.0949 - ERROR - graphrag.index.run.run_pipeline - error running workflow extract_graph
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/run/run_pipeline.py", line 121, in _run_pipeline
    result = await workflow_function(config, context)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/workflows/extract_graph.py", line 50, in run_workflow
    entities, relationships, raw_entities, raw_relationships = await extract_graph(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/workflows/extract_graph.py", line 95, in extract_graph
    extracted_entities, extracted_relationships = await extractor(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/operations/extract_graph/extract_graph.py", line 79, in extract_graph
    entities = _merge_entities(entity_dfs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/operations/extract_graph/extract_graph.py", line 103, in _merge_entities
    all_entities.groupby(["title", "type"], sort=False)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/pandas/core/frame.py", line 9210, in groupby
    return DataFrameGroupBy(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/pandas/core/groupby/groupby.py", line 1331, in __init__
    grouper, exclusions, obj = get_grouper(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/pandas/core/groupby/grouper.py", line 1043, in get_grouper
    raise KeyError(gpr)
KeyError: 'title'
2025-11-15 13:27:40.0954 - ERROR - graphrag.api.index - Workflow extract_graph completed with errors
2025-11-15 13:27:40.0955 - ERROR - graphrag.cli.index - Errors occurred during the pipeline run, see logs for more details.
2025-11-15 13:29:30.0958 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-15 13:29:31.0006 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-15 13:29:31.0006 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-15 13:29:31.0007 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-15 13:29:31.0007 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-15 13:29:31.0007 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-15 13:29:31.0007 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-15 13:29:31.0007 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-15 13:29:31.0007 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-15 13:29:31.0007 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-15 13:29:31.0008 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-15 13:29:31.0008 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-15 13:29:31.0009 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-15 13:29:31.0009 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-15 13:29:31.0009 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-15 13:29:31.0009 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-15 13:29:31.0017 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-15 13:29:31.0017 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-15 13:29:31.0017 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-15 13:29:31.0041 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-15 13:29:31.0044 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-15 13:29:31.0044 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 13:29:31.0062 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-15 13:29:31.0065 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-15 13:29:31.0066 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-15 13:29:31.0067 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-15 13:29:31.0068 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-15 13:29:31.0069 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-15 13:29:31.0070 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-15 13:29:31.0072 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-15 13:29:31.0074 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-15 13:29:31.0075 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-15 13:29:31.0086 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-15 13:29:31.0086 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-15 13:29:31.0089 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-15 13:29:31.0089 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 13:29:31.0092 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 13:29:31.0103 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-15 13:29:31.0103 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-15 13:29:31.0107 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-15 13:29:31.0107 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 13:29:31.0112 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-15 13:29:31.0125 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-15 13:29:31.0126 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-15 13:29:31.0126 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-15 13:29:31.0127 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-15 13:29:31.0127 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-15 13:29:31.0127 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-15 13:29:31.0127 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-15 13:29:31.0128 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-15 13:29:31.0128 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-15 13:29:31.0130 - ERROR - graphrag.index.run.run_pipeline - error running workflow extract_graph
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/run/run_pipeline.py", line 121, in _run_pipeline
    result = await workflow_function(config, context)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/workflows/extract_graph.py", line 50, in run_workflow
    entities, relationships, raw_entities, raw_relationships = await extract_graph(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/workflows/extract_graph.py", line 95, in extract_graph
    extracted_entities, extracted_relationships = await extractor(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/operations/extract_graph/extract_graph.py", line 79, in extract_graph
    entities = _merge_entities(entity_dfs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/operations/extract_graph/extract_graph.py", line 103, in _merge_entities
    all_entities.groupby(["title", "type"], sort=False)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/pandas/core/frame.py", line 9210, in groupby
    return DataFrameGroupBy(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/pandas/core/groupby/groupby.py", line 1331, in __init__
    grouper, exclusions, obj = get_grouper(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/pandas/core/groupby/grouper.py", line 1043, in get_grouper
    raise KeyError(gpr)
KeyError: 'title'
2025-11-15 13:29:31.0134 - ERROR - graphrag.api.index - Workflow extract_graph completed with errors
2025-11-15 13:29:31.0135 - ERROR - graphrag.cli.index - Errors occurred during the pipeline run, see logs for more details.
2025-11-15 13:31:20.0151 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-15 13:31:20.0200 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-15 13:31:20.0200 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-15 13:31:20.0201 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-15 13:31:20.0201 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-15 13:31:20.0201 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-15 13:31:20.0201 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-15 13:31:20.0201 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-15 13:31:20.0201 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-15 13:31:20.0201 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-15 13:31:20.0202 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-15 13:31:20.0202 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-15 13:31:20.0203 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-15 13:31:20.0203 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-15 13:31:20.0203 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-15 13:31:20.0203 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-15 13:31:20.0211 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-15 13:31:20.0212 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-15 13:31:20.0212 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-15 13:31:20.0235 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-15 13:31:20.0238 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-15 13:31:20.0239 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 13:31:20.0253 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-15 13:31:20.0255 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-15 13:31:20.0256 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-15 13:31:20.0257 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-15 13:31:20.0258 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-15 13:31:20.0259 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-15 13:31:20.0259 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-15 13:31:20.0260 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-15 13:31:20.0261 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-15 13:31:20.0262 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-15 13:31:20.0270 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-15 13:31:20.0270 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-15 13:31:20.0273 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-15 13:31:20.0273 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 13:31:20.0275 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 13:31:20.0287 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-15 13:31:20.0287 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-15 13:31:20.0291 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-15 13:31:20.0291 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 13:31:20.0295 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-15 13:35:48.0868 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-15 13:36:25.0928 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-15 13:36:25.0928 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-15 13:36:25.0928 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-15 13:36:25.0928 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-15 13:36:25.0928 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-15 13:36:25.0928 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-15 13:36:25.0928 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-15 13:36:25.0929 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-15 13:36:40.0720 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-15 13:36:41.0747 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-15 13:36:41.0747 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-15 13:36:41.0748 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-15 13:36:41.0748 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-15 13:36:41.0748 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-15 13:36:41.0748 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-15 13:36:41.0748 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-15 13:36:41.0748 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-15 13:36:41.0748 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-15 13:36:41.0749 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-15 13:36:41.0749 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-15 13:36:41.0750 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-15 13:36:41.0750 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-15 13:36:41.0750 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-15 13:36:41.0750 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-15 13:36:41.0757 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-15 13:36:41.0757 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-15 13:36:41.0757 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-15 13:36:41.0761 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-15 13:36:41.0763 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-15 13:36:41.0763 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 13:36:41.0770 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-15 13:36:41.0773 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-15 13:36:41.0774 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-15 13:36:41.0775 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-15 13:36:41.0775 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-15 13:36:41.0776 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-15 13:36:41.0777 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-15 13:36:41.0778 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-15 13:36:41.0779 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-15 13:36:41.0780 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-15 13:36:41.0784 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-15 13:36:41.0784 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-15 13:36:41.0787 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-15 13:36:41.0787 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 13:36:41.0790 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 13:36:41.0798 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-15 13:36:41.0798 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-15 13:36:41.0803 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-15 13:36:41.0803 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 13:36:41.0808 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-15 13:36:41.0859 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-15 13:37:26.0432 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-15 13:37:26.0432 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-15 13:37:26.0432 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-15 13:37:26.0432 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-15 13:37:26.0432 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-15 13:37:26.0433 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-15 13:37:26.0433 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-15 13:37:26.0433 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-15 13:37:56.0824 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-15 13:37:56.0871 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-15 13:37:56.0871 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-15 13:37:56.0871 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-15 13:37:56.0872 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-15 13:37:56.0872 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-15 13:37:56.0872 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-15 13:37:56.0872 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-15 13:37:56.0872 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-15 13:37:56.0872 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-15 13:37:56.0872 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-15 13:37:56.0872 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-15 13:37:56.0873 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-15 13:37:56.0873 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-15 13:37:56.0873 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-15 13:37:56.0874 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-15 13:37:56.0879 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-15 13:37:56.0880 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-15 13:37:56.0880 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-15 13:37:56.0883 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-15 13:37:56.0886 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-15 13:37:56.0886 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 13:37:56.0892 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-15 13:37:56.0895 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-15 13:37:56.0896 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-15 13:37:56.0897 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-15 13:37:56.0897 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-15 13:37:56.0898 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-15 13:37:56.0899 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-15 13:37:56.0900 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-15 13:37:56.0900 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-15 13:37:56.0901 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-15 13:37:56.0906 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-15 13:37:56.0906 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-15 13:37:56.0908 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-15 13:37:56.0909 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 13:37:56.0912 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 13:37:56.0920 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-15 13:37:56.0920 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-15 13:37:56.0924 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-15 13:37:56.0925 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 13:37:56.0930 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-15 13:44:23.0360 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-15 13:44:24.0413 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-15 13:44:24.0413 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-15 13:44:24.0413 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-15 13:44:24.0414 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-15 13:44:24.0414 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-15 13:44:24.0414 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-15 13:44:24.0414 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-15 13:44:24.0414 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-15 13:44:24.0414 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-15 13:44:24.0415 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-15 13:44:24.0415 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-15 13:44:24.0416 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-15 13:44:24.0416 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-15 13:44:24.0416 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-15 13:44:24.0416 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-15 13:44:24.0425 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-15 13:44:24.0425 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-15 13:44:24.0425 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-15 13:44:24.0453 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-15 13:44:24.0456 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-15 13:44:24.0456 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 13:44:24.0472 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-15 13:44:24.0475 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-15 13:44:24.0476 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-15 13:44:24.0477 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-15 13:44:24.0478 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-15 13:44:24.0479 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-15 13:44:24.0480 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-15 13:44:24.0480 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-15 13:44:24.0481 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-15 13:44:24.0482 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-15 13:44:24.0491 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-15 13:44:24.0491 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-15 13:44:24.0494 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-15 13:44:24.0494 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 13:44:24.0496 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 13:44:24.0508 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-15 13:44:24.0508 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-15 13:44:24.0513 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-15 13:44:24.0513 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 13:44:24.0518 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-15 13:46:50.0830 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-15 13:46:50.0830 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-15 13:46:50.0830 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-15 13:46:50.0830 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-15 13:46:50.0830 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-15 13:46:50.0830 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-15 13:46:50.0831 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-15 13:46:50.0831 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-15 13:46:50.0831 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-15 13:52:15.0375 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-15 13:52:15.0862 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-15 13:52:15.0863 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-15 13:52:15.0863 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "Current Table",
            "Model",
            "CTE",
            "Source Table",
            "Column",
            "Function",
            "Derived Column",
            "Data Quality Rule",
            "Business Concept",
            "Data Grain"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-15 13:52:15.0863 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-15 13:52:15.0864 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-15 13:52:15.0864 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-15 13:52:15.0864 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-15 13:52:15.0864 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-15 13:52:15.0864 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-15 13:52:15.0864 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-15 13:52:15.0864 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-15 13:52:15.0865 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-15 13:52:15.0865 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-15 13:52:15.0865 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-15 13:52:15.0865 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-15 13:52:15.0870 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-15 13:52:15.0871 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-15 13:52:15.0871 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-15 13:52:15.0874 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-15 13:52:15.0876 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-15 13:52:15.0877 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 13:52:15.0882 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-15 13:52:15.0885 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-15 13:52:15.0886 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-15 13:52:15.0887 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-15 13:52:15.0887 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-15 13:52:15.0888 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-15 13:52:15.0889 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-15 13:52:15.0890 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-15 13:52:15.0891 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-15 13:52:15.0891 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-15 13:52:15.0895 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-15 13:52:15.0895 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-15 13:52:15.0898 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-15 13:52:15.0898 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 13:52:15.0901 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 13:52:15.0908 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-15 13:52:15.0908 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-15 13:52:15.0912 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-15 13:52:15.0913 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 13:52:15.0916 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-15 13:56:19.0395 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-15 13:57:06.0990 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-15 13:57:36.0383 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-15 13:59:18.0354 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-15 14:01:31.0002 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=555.04 seconds
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client_reqrep.py", line 532, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/streams.py", line 672, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1529, in request
    response = await self._client.send(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/usr/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 452, in make_openai_chat_completion_request
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1547, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=555.04 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 280, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=555.04 seconds
2025-11-15 14:01:56.0952 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-15 14:01:56.0952 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-15 14:01:56.0952 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-15 14:01:56.0952 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-15 14:01:56.0952 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-15 14:02:11.0834 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-15 14:02:12.0300 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-15 14:02:12.0300 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-15 14:02:12.0300 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "Current Table",
            "Model",
            "CTE",
            "Source Table",
            "Column",
            "Function",
            "Derived Column",
            "Data Quality Rule",
            "Business Concept",
            "Data Grain"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-15 14:02:12.0301 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-15 14:02:12.0301 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-15 14:02:12.0301 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-15 14:02:12.0301 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-15 14:02:12.0301 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-15 14:02:12.0301 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-15 14:02:12.0302 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-15 14:02:12.0302 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-15 14:02:12.0302 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-15 14:02:12.0303 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-15 14:02:12.0303 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-15 14:02:12.0303 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-15 14:02:12.0308 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-15 14:02:12.0308 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-15 14:02:12.0308 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-15 14:02:12.0311 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-15 14:02:12.0314 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-15 14:02:12.0314 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 14:02:12.0320 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-15 14:02:12.0322 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-15 14:02:12.0323 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-15 14:02:12.0324 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-15 14:02:12.0325 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-15 14:02:12.0325 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-15 14:02:12.0326 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-15 14:02:12.0327 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-15 14:02:12.0327 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-15 14:02:12.0328 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-15 14:02:12.0332 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-15 14:02:12.0333 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-15 14:02:12.0336 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-15 14:02:12.0336 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 14:02:12.0339 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 14:02:12.0348 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-15 14:02:12.0348 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-15 14:02:12.0353 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-15 14:02:12.0353 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 14:02:12.0357 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-15 14:02:12.0410 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-15 14:02:12.0410 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-15 14:02:12.0411 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-15 14:02:12.0411 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-15 14:03:47.0119 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-15 14:04:31.0351 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-15 14:05:01.0351 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-15 14:06:06.0379 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-15 14:06:23.0450 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-15 14:06:39.0529 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-15 14:06:39.0573 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-15 14:06:39.0573 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-15 14:06:39.0574 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "Current Table",
            "Model",
            "CTE",
            "Source Table",
            "Column",
            "Function",
            "Derived Column",
            "Data Quality Rule",
            "Business Concept",
            "Data Grain"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-15 14:06:39.0574 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-15 14:06:39.0574 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-15 14:06:39.0574 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-15 14:06:39.0574 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-15 14:06:39.0574 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-15 14:06:39.0574 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-15 14:06:39.0575 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-15 14:06:39.0575 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-15 14:06:39.0576 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-15 14:06:39.0576 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-15 14:06:39.0576 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-15 14:06:39.0577 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-15 14:06:39.0583 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-15 14:06:39.0583 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-15 14:06:39.0584 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-15 14:06:39.0587 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-15 14:06:39.0590 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-15 14:06:39.0590 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 14:06:39.0596 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-15 14:06:39.0599 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-15 14:06:39.0600 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-15 14:06:39.0600 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-15 14:06:39.0601 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-15 14:06:39.0602 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-15 14:06:39.0603 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-15 14:06:39.0604 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-15 14:06:39.0604 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-15 14:06:39.0605 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-15 14:06:39.0610 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-15 14:06:39.0610 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-15 14:06:39.0613 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-15 14:06:39.0613 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 14:06:39.0616 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 14:06:39.0624 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-15 14:06:39.0625 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-15 14:06:39.0629 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-15 14:06:39.0629 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 14:06:39.0635 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-15 14:06:39.0678 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-15 14:06:39.0678 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-15 14:06:39.0678 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-15 14:06:39.0679 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-15 14:06:39.0680 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-15 14:06:39.0681 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-15 14:06:39.0681 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-15 14:06:39.0681 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-15 14:07:28.0545 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-15 14:07:28.0546 - ERROR - graphrag.index.run.run_pipeline - error running workflow extract_graph
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/run/run_pipeline.py", line 121, in _run_pipeline
    result = await workflow_function(config, context)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/workflows/extract_graph.py", line 50, in run_workflow
    entities, relationships, raw_entities, raw_relationships = await extract_graph(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/workflows/extract_graph.py", line 95, in extract_graph
    extracted_entities, extracted_relationships = await extractor(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/operations/extract_graph/extract_graph.py", line 79, in extract_graph
    entities = _merge_entities(entity_dfs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/operations/extract_graph/extract_graph.py", line 103, in _merge_entities
    all_entities.groupby(["title", "type"], sort=False)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/pandas/core/frame.py", line 9210, in groupby
    return DataFrameGroupBy(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/pandas/core/groupby/groupby.py", line 1331, in __init__
    grouper, exclusions, obj = get_grouper(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/pandas/core/groupby/grouper.py", line 1043, in get_grouper
    raise KeyError(gpr)
KeyError: 'title'
2025-11-15 14:07:28.0550 - ERROR - graphrag.api.index - Workflow extract_graph completed with errors
2025-11-15 14:07:28.0552 - ERROR - graphrag.cli.index - Errors occurred during the pipeline run, see logs for more details.
2025-11-15 14:09:01.0689 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-15 14:09:01.0734 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-15 14:09:01.0734 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-15 14:09:01.0734 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "Current Table",
            "Model",
            "CTE",
            "Source Table",
            "Column",
            "Function",
            "Derived Column",
            "Data Quality Rule",
            "Business Concept",
            "Data Grain"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-15 14:09:01.0735 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-15 14:09:01.0735 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-15 14:09:01.0735 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-15 14:09:01.0735 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-15 14:09:01.0735 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-15 14:09:01.0735 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-15 14:09:01.0735 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-15 14:09:01.0735 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-15 14:09:01.0736 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-15 14:09:01.0736 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-15 14:09:01.0736 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-15 14:09:01.0736 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-15 14:09:01.0741 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-15 14:09:01.0742 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-15 14:09:01.0742 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-15 14:09:01.0744 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-15 14:09:01.0747 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-15 14:09:01.0747 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 14:09:01.0754 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-15 14:09:01.0757 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-15 14:09:01.0758 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-15 14:09:01.0759 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-15 14:09:01.0760 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-15 14:09:01.0761 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-15 14:09:01.0761 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-15 14:09:01.0762 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-15 14:09:01.0763 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-15 14:09:01.0764 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-15 14:09:01.0769 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-15 14:09:01.0769 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-15 14:09:01.0772 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-15 14:09:01.0772 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 14:09:01.0775 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 14:09:01.0784 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-15 14:09:01.0784 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-15 14:09:01.0789 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-15 14:09:01.0789 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 14:09:01.0794 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-15 14:14:09.0064 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-15 14:14:09.0064 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-15 14:14:09.0064 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-15 14:14:09.0064 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-15 14:14:09.0064 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-15 14:14:09.0064 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-15 14:14:09.0065 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-15 14:14:09.0065 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-15 14:14:09.0065 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-15 14:14:23.0723 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-15 14:14:24.0209 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-15 14:14:24.0209 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-15 14:14:24.0209 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "Current Table",
            "Model",
            "CTE",
            "Source Table",
            "Column",
            "Function",
            "Derived Column",
            "Data Quality Rule",
            "Business Concept",
            "Data Grain"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-15 14:14:24.0210 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-15 14:14:24.0210 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-15 14:14:24.0210 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-15 14:14:24.0210 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-15 14:14:24.0210 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-15 14:14:24.0210 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-15 14:14:24.0211 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-15 14:14:24.0211 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-15 14:14:24.0212 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-15 14:14:24.0212 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-15 14:14:24.0212 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-15 14:14:24.0212 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-15 14:14:24.0218 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-15 14:14:24.0218 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-15 14:14:24.0218 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-15 14:14:24.0223 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-15 14:14:24.0226 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-15 14:14:24.0226 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 14:14:24.0232 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-15 14:14:24.0235 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-15 14:14:24.0237 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-15 14:14:24.0238 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-15 14:14:24.0239 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-15 14:14:24.0240 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-15 14:14:24.0240 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-15 14:14:24.0241 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-15 14:14:24.0242 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-15 14:14:24.0243 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-15 14:14:24.0247 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-15 14:14:24.0247 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-15 14:14:24.0250 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-15 14:14:24.0251 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 14:14:24.0253 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 14:14:24.0262 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-15 14:14:24.0262 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-15 14:14:24.0266 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-15 14:14:24.0267 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 14:14:24.0271 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-15 14:19:02.0044 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-15 14:19:02.0044 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-15 14:19:02.0044 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-15 14:19:02.0045 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-15 14:19:02.0045 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-15 14:19:02.0045 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-15 14:19:02.0045 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-15 14:19:02.0045 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-15 14:19:02.0045 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-15 14:19:18.0585 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-15 14:19:18.0629 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-15 14:19:18.0629 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-15 14:19:18.0629 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "Current Table",
            "Model",
            "CTE",
            "Source Table",
            "Column",
            "Function",
            "Derived Column",
            "Data Quality Rule",
            "Business Concept",
            "Data Grain"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-15 14:19:18.0630 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-15 14:19:18.0630 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-15 14:19:18.0630 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-15 14:19:18.0630 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-15 14:19:18.0630 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-15 14:19:18.0630 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-15 14:19:18.0631 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-15 14:19:18.0631 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-15 14:19:18.0631 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-15 14:19:18.0631 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-15 14:19:18.0631 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-15 14:19:18.0632 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-15 14:19:18.0638 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-15 14:19:18.0638 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-15 14:19:18.0638 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-15 14:19:18.0641 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-15 14:19:18.0643 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-15 14:19:18.0643 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 14:19:18.0649 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-15 14:19:18.0652 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-15 14:19:18.0653 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-15 14:19:18.0654 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-15 14:19:18.0655 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-15 14:19:18.0656 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-15 14:19:18.0656 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-15 14:19:18.0657 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-15 14:19:18.0658 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-15 14:19:18.0659 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-15 14:19:18.0662 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-15 14:19:18.0663 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-15 14:19:18.0665 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-15 14:19:18.0666 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 14:19:18.0668 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 14:19:18.0677 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-15 14:19:18.0677 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-15 14:19:18.0681 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-15 14:19:18.0681 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 14:19:18.0685 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-15 14:19:51.0675 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-15 14:20:47.0735 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-15 14:21:42.0300 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-15 14:23:01.0258 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-15 14:23:30.0845 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-15 14:26:12.0792 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-15 14:28:37.0135 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=558.41 seconds
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client_reqrep.py", line 532, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/streams.py", line 672, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1529, in request
    response = await self._client.send(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/usr/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 452, in make_openai_chat_completion_request
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1547, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=558.41 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 280, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=558.41 seconds
2025-11-15 14:28:37.0306 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=558.57 seconds
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client_reqrep.py", line 532, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/streams.py", line 672, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1529, in request
    response = await self._client.send(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/usr/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 452, in make_openai_chat_completion_request
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1547, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=558.57 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 280, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=558.57 seconds
2025-11-15 14:28:37.0313 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=558.59 seconds
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client_reqrep.py", line 532, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/streams.py", line 672, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1529, in request
    response = await self._client.send(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/usr/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 452, in make_openai_chat_completion_request
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1547, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=558.59 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 280, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=558.59 seconds
2025-11-15 14:30:56.0984 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-15 14:30:56.0984 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-15 14:30:56.0985 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-15 14:31:13.0013 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-15 14:31:13.0490 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-15 14:31:13.0490 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-15 14:31:13.0490 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 500.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "Current Table",
            "Model",
            "CTE",
            "Source Table",
            "Column",
            "Function",
            "Derived Column",
            "Data Quality Rule",
            "Business Concept",
            "Data Grain"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-15 14:31:13.0490 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-15 14:31:13.0490 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-15 14:31:13.0491 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-15 14:31:13.0491 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-15 14:31:13.0491 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-15 14:31:13.0491 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-15 14:31:13.0491 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-15 14:31:13.0491 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-15 14:31:13.0492 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-15 14:31:13.0492 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-15 14:31:13.0492 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-15 14:31:13.0493 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-15 14:31:13.0497 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-15 14:31:13.0498 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-15 14:31:13.0498 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-15 14:31:13.0500 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-15 14:31:13.0503 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-15 14:31:13.0503 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 14:31:13.0508 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-15 14:31:13.0510 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-15 14:31:13.0511 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-15 14:31:13.0512 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-15 14:31:13.0513 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-15 14:31:13.0514 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-15 14:31:13.0515 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-15 14:31:13.0516 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-15 14:31:13.0516 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-15 14:31:13.0517 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-15 14:31:13.0521 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-15 14:31:13.0521 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-15 14:31:13.0524 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-15 14:31:13.0524 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 14:31:13.0526 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 14:31:13.0534 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-15 14:31:13.0535 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-15 14:31:13.0539 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-15 14:31:13.0539 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 14:31:13.0542 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-15 14:31:13.0587 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-15 14:31:13.0588 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-15 14:31:13.0588 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-15 14:31:13.0589 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-15 14:31:13.0589 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-15 14:31:13.0590 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-15 14:32:02.0124 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-15 14:36:40.0803 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-15 14:36:40.0804 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-15 14:37:39.0397 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-15 14:37:39.0892 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-15 14:37:39.0892 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-15 14:37:39.0893 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 500.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "Current Table",
            "Model",
            "CTE",
            "Source Table",
            "Column",
            "Function",
            "Derived Column",
            "Data Quality Rule",
            "Business Concept",
            "Data Grain"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-15 14:37:39.0893 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-15 14:37:39.0893 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-15 14:37:39.0893 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-15 14:37:39.0894 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-15 14:37:39.0894 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-15 14:37:39.0894 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-15 14:37:39.0894 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-15 14:37:39.0894 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-15 14:37:39.0895 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-15 14:37:39.0895 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-15 14:37:39.0895 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-15 14:37:39.0895 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-15 14:37:39.0900 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-15 14:37:39.0901 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-15 14:37:39.0901 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-15 14:37:39.0904 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-15 14:37:39.0907 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-15 14:37:39.0907 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 14:37:39.0912 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-15 14:37:39.0915 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-15 14:37:39.0916 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-15 14:37:39.0917 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-15 14:37:39.0918 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-15 14:37:39.0918 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-15 14:37:39.0919 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-15 14:37:39.0920 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-15 14:37:39.0921 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-15 14:37:39.0922 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-15 14:37:39.0926 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-15 14:37:39.0926 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-15 14:37:39.0929 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-15 14:37:39.0929 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 14:37:39.0932 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 14:37:39.0939 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-15 14:37:39.0940 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-15 14:37:39.0943 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-15 14:37:39.0944 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 14:37:39.0946 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-15 14:37:39.0991 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-15 14:37:39.0991 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-15 14:37:39.0992 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-15 14:37:39.0993 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-15 14:37:39.0993 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-15 14:37:39.0994 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-15 14:37:39.0994 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-15 14:38:20.0498 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-15 14:46:49.0722 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-15 14:46:49.0724 - ERROR - graphrag.index.run.run_pipeline - error running workflow extract_graph
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/run/run_pipeline.py", line 121, in _run_pipeline
    result = await workflow_function(config, context)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/workflows/extract_graph.py", line 50, in run_workflow
    entities, relationships, raw_entities, raw_relationships = await extract_graph(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/workflows/extract_graph.py", line 95, in extract_graph
    extracted_entities, extracted_relationships = await extractor(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/operations/extract_graph/extract_graph.py", line 79, in extract_graph
    entities = _merge_entities(entity_dfs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/operations/extract_graph/extract_graph.py", line 103, in _merge_entities
    all_entities.groupby(["title", "type"], sort=False)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/pandas/core/frame.py", line 9210, in groupby
    return DataFrameGroupBy(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/pandas/core/groupby/groupby.py", line 1331, in __init__
    grouper, exclusions, obj = get_grouper(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/pandas/core/groupby/grouper.py", line 1043, in get_grouper
    raise KeyError(gpr)
KeyError: 'title'
2025-11-15 14:46:49.0726 - ERROR - graphrag.api.index - Workflow extract_graph completed with errors
2025-11-15 14:46:49.0727 - ERROR - graphrag.cli.index - Errors occurred during the pipeline run, see logs for more details.
2025-11-15 14:48:45.0734 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-15 14:48:46.0265 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-15 14:48:46.0265 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-15 14:48:46.0266 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 500.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "Current Table",
            "Model",
            "CTE",
            "Source Table",
            "Column",
            "Function",
            "Derived Column",
            "Data Quality Rule",
            "Business Concept",
            "Data Grain"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-15 14:48:46.0266 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-15 14:48:46.0266 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-15 14:48:46.0266 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-15 14:48:46.0266 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-15 14:48:46.0266 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-15 14:48:46.0266 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-15 14:48:46.0267 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-15 14:48:46.0267 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-15 14:48:46.0268 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-15 14:48:46.0268 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-15 14:48:46.0268 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-15 14:48:46.0268 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-15 14:48:46.0273 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-15 14:48:46.0274 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-15 14:48:46.0274 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-15 14:48:46.0277 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-15 14:48:46.0280 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-15 14:48:46.0280 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 14:48:46.0286 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-15 14:48:46.0289 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-15 14:48:46.0290 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-15 14:48:46.0290 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-15 14:48:46.0291 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-15 14:48:46.0292 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-15 14:48:46.0293 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-15 14:48:46.0293 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-15 14:48:46.0294 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-15 14:48:46.0295 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-15 14:48:46.0299 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-15 14:48:46.0299 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-15 14:48:46.0301 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-15 14:48:46.0302 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 14:48:46.0304 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 14:48:46.0312 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-15 14:48:46.0312 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-15 14:48:46.0316 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-15 14:48:46.0316 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 14:48:46.0319 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-15 14:50:45.0927 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-15 14:50:45.0928 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-15 14:50:45.0928 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-15 14:50:45.0928 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-15 14:50:45.0928 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-15 14:50:45.0928 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-15 14:50:45.0928 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-15 14:50:45.0928 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-15 14:50:45.0928 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-15 14:51:31.0737 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-15 14:51:31.0775 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-15 14:51:31.0775 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-15 14:51:31.0776 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 500.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": "medium",
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "Current Table",
            "Model",
            "CTE",
            "Source Table",
            "Column",
            "Function",
            "Derived Column",
            "Data Quality Rule",
            "Business Concept",
            "Data Grain"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-15 14:51:31.0776 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-15 14:51:31.0776 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-15 14:51:31.0776 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-15 14:51:31.0776 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-15 14:51:31.0776 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-15 14:51:31.0776 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-15 14:51:31.0777 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-15 14:51:31.0777 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-15 14:51:31.0777 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-15 14:51:31.0777 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-15 14:51:31.0778 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-15 14:51:31.0778 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-15 14:51:31.0782 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-15 14:51:31.0782 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-15 14:51:31.0782 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-15 14:51:31.0786 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-15 14:51:31.0789 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-15 14:51:31.0789 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 14:51:31.0794 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-15 14:51:31.0796 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-15 14:51:31.0797 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-15 14:51:31.0797 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-15 14:51:31.0798 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-15 14:51:31.0799 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-15 14:51:31.0800 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-15 14:51:31.0800 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-15 14:51:31.0801 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-15 14:51:31.0802 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-15 14:51:31.0806 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-15 14:51:31.0806 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-15 14:51:31.0809 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-15 14:51:31.0809 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 14:51:31.0812 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 14:51:31.0820 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-15 14:51:31.0820 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-15 14:51:31.0824 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-15 14:51:31.0824 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 14:51:31.0827 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-15 14:57:14.0746 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-15 14:58:07.0192 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-15 15:02:52.0893 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-15 15:03:32.0116 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-15 15:04:01.0726 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-15 15:12:02.0593 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-15 15:12:44.0400 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-15 15:19:11.0172 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=500.0, time taken=1561.26 seconds
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client_reqrep.py", line 532, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/streams.py", line 672, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1529, in request
    response = await self._client.send(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/usr/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 452, in make_openai_chat_completion_request
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1547, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=500.0, time taken=1561.26 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 280, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=500.0, time taken=1561.26 seconds
2025-11-15 15:19:51.0939 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=500.0, time taken=1561.56 seconds
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/client_reqrep.py", line 532, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/aiohttp/streams.py", line 672, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1529, in request
    response = await self._client.send(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/usr/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 452, in make_openai_chat_completion_request
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
    return await self._post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/openai/_base_client.py", line 1547, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=500.0, time taken=1561.56 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 280, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=500.0, time taken=1561.56 seconds
2025-11-15 15:20:39.0019 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-15 15:20:39.0020 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-15 15:20:54.0583 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-15 15:20:55.0365 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-15 15:20:55.0365 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-15 15:20:55.0365 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 500.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": "medium",
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "Current Table",
            "Model",
            "CTE",
            "Source Table",
            "Column",
            "Function",
            "Derived Column",
            "Data Quality Rule",
            "Business Concept",
            "Data Grain"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-15 15:20:55.0366 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-15 15:20:55.0366 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-15 15:20:55.0366 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-15 15:20:55.0366 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-15 15:20:55.0366 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-15 15:20:55.0366 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-15 15:20:55.0367 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-15 15:20:55.0367 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-15 15:20:55.0368 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-15 15:20:55.0368 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-15 15:20:55.0368 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-15 15:20:55.0368 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-15 15:20:55.0375 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-15 15:20:55.0375 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-15 15:20:55.0375 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-15 15:20:55.0381 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-15 15:20:55.0384 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-15 15:20:55.0384 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 15:20:55.0392 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-15 15:20:55.0395 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-15 15:20:55.0397 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-15 15:20:55.0399 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-15 15:20:55.0401 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-15 15:20:55.0404 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-15 15:20:55.0405 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-15 15:20:55.0406 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-15 15:20:55.0407 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-15 15:20:55.0408 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-15 15:20:55.0412 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-15 15:20:55.0412 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-15 15:20:55.0415 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-15 15:20:55.0415 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 15:20:55.0418 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 15:20:55.0429 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-15 15:20:55.0429 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-15 15:20:55.0434 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-15 15:20:55.0434 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 15:20:55.0438 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-15 15:20:55.0482 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-15 15:20:55.0484 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-15 15:20:55.0485 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-15 15:20:55.0485 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-15 15:20:55.0485 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-15 15:20:55.0486 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-15 15:20:55.0486 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-15 15:21:44.0586 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-15 15:29:08.0469 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-15 15:29:31.0704 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-15 15:29:32.0401 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-15 15:29:32.0401 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-15 15:29:32.0402 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 500.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "Current Table",
            "Model",
            "CTE",
            "Source Table",
            "Column",
            "Function",
            "Derived Column",
            "Data Quality Rule",
            "Business Concept",
            "Data Grain"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-15 15:29:32.0403 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-15 15:29:32.0403 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-15 15:29:32.0403 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-15 15:29:32.0403 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-15 15:29:32.0403 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-15 15:29:32.0403 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-15 15:29:32.0404 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-15 15:29:32.0404 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-15 15:29:32.0405 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-15 15:29:32.0405 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-15 15:29:32.0405 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-15 15:29:32.0406 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-15 15:29:32.0410 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-15 15:29:32.0411 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-15 15:29:32.0411 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-15 15:29:32.0415 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-15 15:29:32.0418 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-15 15:29:32.0418 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 15:29:32.0425 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-15 15:29:32.0428 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-15 15:29:32.0429 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-15 15:29:32.0430 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-15 15:29:32.0431 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-15 15:29:32.0432 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-15 15:29:32.0433 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-15 15:29:32.0434 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-15 15:29:32.0434 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-15 15:29:32.0435 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-15 15:29:32.0440 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-15 15:29:32.0440 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-15 15:29:32.0443 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-15 15:29:32.0443 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 15:29:32.0445 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 15:29:32.0453 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-15 15:29:32.0453 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-15 15:29:32.0457 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-15 15:29:32.0457 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 15:29:32.0461 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-15 15:35:33.0294 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-15 15:35:33.0295 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-15 15:35:33.0295 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-15 15:35:33.0295 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-15 15:35:33.0295 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-15 15:35:33.0295 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-15 15:35:33.0295 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-15 15:35:33.0295 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-15 15:35:33.0295 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-15 15:36:49.0754 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-15 15:36:50.0203 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-15 15:36:50.0203 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-15 15:36:50.0204 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "qwen3:14b",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 500.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "Current Table",
            "Model",
            "CTE",
            "Source Table",
            "Column",
            "Function",
            "Derived Column",
            "Data Quality Rule",
            "Business Concept",
            "Data Grain"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-15 15:36:50.0204 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-15 15:36:50.0204 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-15 15:36:50.0204 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-15 15:36:50.0204 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-15 15:36:50.0204 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-15 15:36:50.0204 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-15 15:36:50.0205 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-15 15:36:50.0205 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-15 15:36:50.0206 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-15 15:36:50.0206 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-15 15:36:50.0206 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-15 15:36:50.0206 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-15 15:36:50.0211 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-15 15:36:50.0211 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-15 15:36:50.0211 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-15 15:36:50.0215 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-15 15:36:50.0217 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-15 15:36:50.0217 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 15:36:50.0223 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-15 15:36:50.0226 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-15 15:36:50.0227 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-15 15:36:50.0228 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-15 15:36:50.0229 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-15 15:36:50.0230 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-15 15:36:50.0230 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-15 15:36:50.0231 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-15 15:36:50.0232 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-15 15:36:50.0232 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-15 15:36:50.0236 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-15 15:36:50.0236 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-15 15:36:50.0239 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-15 15:36:50.0239 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 15:36:50.0241 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 15:36:50.0249 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-15 15:36:50.0249 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-15 15:36:50.0253 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-15 15:36:50.0253 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 15:36:50.0256 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-15 15:37:32.0290 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-15 15:38:11.0618 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-15 15:39:00.0010 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-15 15:39:35.0329 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-15 15:46:02.0992 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-15 15:46:39.0568 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-15 15:47:20.0783 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-15 15:48:22.0074 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-15 15:54:50.0426 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-15 15:54:50.0428 - ERROR - graphrag.index.run.run_pipeline - error running workflow extract_graph
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/run/run_pipeline.py", line 121, in _run_pipeline
    result = await workflow_function(config, context)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/workflows/extract_graph.py", line 50, in run_workflow
    entities, relationships, raw_entities, raw_relationships = await extract_graph(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/workflows/extract_graph.py", line 95, in extract_graph
    extracted_entities, extracted_relationships = await extractor(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/operations/extract_graph/extract_graph.py", line 79, in extract_graph
    entities = _merge_entities(entity_dfs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/index/operations/extract_graph/extract_graph.py", line 103, in _merge_entities
    all_entities.groupby(["title", "type"], sort=False)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/pandas/core/frame.py", line 9210, in groupby
    return DataFrameGroupBy(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/pandas/core/groupby/groupby.py", line 1331, in __init__
    grouper, exclusions, obj = get_grouper(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/pandas/core/groupby/grouper.py", line 1043, in get_grouper
    raise KeyError(gpr)
KeyError: 'title'
2025-11-15 15:54:50.0431 - ERROR - graphrag.api.index - Workflow extract_graph completed with errors
2025-11-15 15:54:50.0432 - ERROR - graphrag.cli.index - Errors occurred during the pipeline run, see logs for more details.
2025-11-15 15:57:04.0963 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-15 15:57:05.0565 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-15 15:57:05.0565 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-15 15:57:05.0566 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "gemini",
            "model": "gemini-2.5-flash-lite",
            "encoding_model": "",
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 500.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "gemini",
            "model": "gemini-embedding-001",
            "encoding_model": "",
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "Current Table",
            "Model",
            "CTE",
            "Source Table",
            "Column",
            "Function",
            "Derived Column",
            "Data Quality Rule",
            "Business Concept",
            "Data Grain"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-15 15:57:05.0566 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-15 15:57:05.0566 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-15 15:57:05.0566 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-15 15:57:05.0566 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-15 15:57:05.0566 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-15 15:57:05.0567 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-15 15:57:05.0567 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-15 15:57:05.0567 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-15 15:57:05.0568 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-15 15:57:05.0568 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-15 15:57:05.0568 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-15 15:57:05.0568 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-15 15:57:05.0573 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-15 15:57:05.0573 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-15 15:57:05.0573 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-15 15:57:05.0577 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-15 15:57:05.0579 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-15 15:57:05.0579 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 15:57:05.0585 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-15 15:57:05.0587 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-15 15:57:05.0588 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-15 15:57:05.0589 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-15 15:57:05.0590 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-15 15:57:05.0590 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-15 15:57:05.0591 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-15 15:57:05.0592 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-15 15:57:05.0593 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-15 15:57:05.0594 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-15 15:57:05.0597 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-15 15:57:05.0597 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-15 15:57:05.0600 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-15 15:57:05.0600 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 15:57:05.0603 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 15:57:05.0612 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-15 15:57:05.0612 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-15 15:57:05.0617 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-15 15:57:05.0617 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 15:57:05.0620 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-15 15:57:11.0419 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: GeminiException - {
  "error": {
    "code": 429,
    "message": "Resource has been exhausted (e.g. check quota).",
    "status": "RESOURCE_EXHAUSTED"
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "Resource has been exhausted (e.g. check quota).",
    "status": "RESOURCE_EXHAUSTED"
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1345, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: GeminiException - {
  "error": {
    "code": 429,
    "message": "Resource has been exhausted (e.g. check quota).",
    "status": "RESOURCE_EXHAUSTED"
  }
}

2025-11-15 15:57:11.0438 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.200175416s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.200175416s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.200175416s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}

2025-11-15 15:57:11.0578 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-15 15:57:11.0616 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: GeminiException - {
  "error": {
    "code": 429,
    "message": "Resource has been exhausted (e.g. check quota).",
    "status": "RESOURCE_EXHAUSTED"
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "Resource has been exhausted (e.g. check quota).",
    "status": "RESOURCE_EXHAUSTED"
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1345, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: GeminiException - {
  "error": {
    "code": 429,
    "message": "Resource has been exhausted (e.g. check quota).",
    "status": "RESOURCE_EXHAUSTED"
  }
}

2025-11-15 15:57:11.0846 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-15 15:57:12.0028 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 46.580873696s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "46s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 46.580873696s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "46s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 46.580873696s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "46s"
      }
    ]
  }
}

2025-11-15 15:57:14.0398 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 45.619516153s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "45s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 45.619516153s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "45s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 45.619516153s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "45s"
      }
    ]
  }
}

2025-11-15 15:57:14.0531 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-15 15:57:15.0121 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.860106649s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.860106649s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.860106649s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}

2025-11-15 15:57:15.0141 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-15 15:57:15.0202 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.776301345s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.776301345s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.776301345s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}

2025-11-15 15:57:15.0739 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.219085459s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.219085459s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.219085459s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}

2025-11-15 15:57:16.0381 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 43.545585583s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "43s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 43.545585583s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "43s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 43.545585583s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "43s"
      }
    ]
  }
}

2025-11-15 15:57:17.0466 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 42.412270638s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "42s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 42.412270638s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "42s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 42.412270638s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "42s"
      }
    ]
  }
}

2025-11-15 15:57:19.0561 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 40.224413451s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "40s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 40.224413451s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "40s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 40.224413451s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "40s"
      }
    ]
  }
}

2025-11-15 15:57:19.0635 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 40.148426316s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "40s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 40.148426316s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "40s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 40.148426316s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "40s"
      }
    ]
  }
}

2025-11-15 15:57:20.0290 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 39.4640212s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "39s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 39.4640212s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "39s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 39.4640212s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "39s"
      }
    ]
  }
}

2025-11-15 15:57:20.0859 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 38.868610133s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "38s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 38.868610133s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "38s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 38.868610133s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "38s"
      }
    ]
  }
}

2025-11-15 15:57:22.0576 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.07430882s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.07430882s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.07430882s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}

2025-11-15 15:57:27.0817 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 31.596444848s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "31s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 31.596444848s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "31s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 31.596444848s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "31s"
      }
    ]
  }
}

2025-11-15 15:57:28.0376 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 31.010889004s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "31s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 31.010889004s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "31s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 31.010889004s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "31s"
      }
    ]
  }
}

2025-11-15 15:57:28.0549 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 30.834452826s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "30s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 30.834452826s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "30s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 30.834452826s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "30s"
      }
    ]
  }
}

2025-11-15 15:57:29.0959 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 29.358762307s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 29.358762307s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 29.358762307s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}

2025-11-15 15:57:31.0377 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 27.874629687s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 27.874629687s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 27.874629687s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}

2025-11-15 15:57:44.0774 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.879862997s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.879862997s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.879862997s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 15:57:45.0025 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.618909789s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.618909789s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.618909789s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 15:57:45.0184 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.451853458s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.451853458s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.451853458s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 15:57:48.0516 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 11.482460706s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "11s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 11.482460706s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "11s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 11.482460706s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "11s"
      }
    ]
  }
}

2025-11-15 15:57:49.0789 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 10.147680511s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "10s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 10.147680511s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "10s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 10.147680511s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "10s"
      }
    ]
  }
}

2025-11-15 15:58:16.0601 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-15 15:58:16.0601 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-15 15:58:16.0601 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-15 15:58:16.0601 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-15 15:58:16.0601 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-15 15:59:31.0397 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-11-15 15:59:32.0045 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-11-15 15:59:32.0045 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-11-15 15:59:32.0046 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/granite/adk_test/generated_text_docs",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "gemini",
            "model": "gemini-2.5-flash-lite",
            "encoding_model": "",
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 500.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "gemini",
            "model": "gemini-embedding-001",
            "encoding_model": "",
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "asyncio",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/granite/adk_test/generated_text_docs/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/granite/adk_test/generated_text_docs/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/granite/adk_test/generated_text_docs/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "Current Table",
            "Model",
            "CTE",
            "Source Table",
            "Column",
            "Function",
            "Derived Column",
            "Data Quality Rule",
            "Business Concept",
            "Data Grain"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-11-15 15:59:32.0046 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-11-15 15:59:32.0046 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-11-15 15:59:32.0046 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/input
2025-11-15 15:59:32.0046 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/output
2025-11-15 15:59:32.0047 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs
2025-11-15 15:59:32.0047 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache
2025-11-15 15:59:32.0047 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-11-15 15:59:32.0047 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-11-15 15:59:32.0048 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-11-15 15:59:32.0048 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/granite/adk_test/generated_text_docs/input
2025-11-15 15:59:32.0048 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-11-15 15:59:32.0048 - INFO - graphrag.storage.file_pipeline_storage - search /home/granite/adk_test/generated_text_docs/input for files matching .*\.txt$
2025-11-15 15:59:32.0053 - INFO - graphrag.index.input.util - Found 9 InputFileType.text files, loading 9
2025-11-15 15:59:32.0054 - INFO - graphrag.index.input.util - Total number of unfiltered text rows: 9
2025-11-15 15:59:32.0054 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 9
2025-11-15 15:59:32.0058 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-11-15 15:59:32.0060 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-11-15 15:59:32.0061 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 15:59:32.0066 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 9 documents
2025-11-15 15:59:32.0068 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/9
2025-11-15 15:59:32.0069 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/9
2025-11-15 15:59:32.0070 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/9
2025-11-15 15:59:32.0070 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/9
2025-11-15 15:59:32.0071 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/9
2025-11-15 15:59:32.0072 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/9
2025-11-15 15:59:32.0072 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/9
2025-11-15 15:59:32.0073 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/9
2025-11-15 15:59:32.0074 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/9
2025-11-15 15:59:32.0078 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-11-15 15:59:32.0078 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-11-15 15:59:32.0081 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-11-15 15:59:32.0082 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-11-15 15:59:32.0084 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 15:59:32.0092 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-11-15 15:59:32.0092 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-11-15 15:59:32.0096 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-11-15 15:59:32.0096 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 15:59:32.0100 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/extract_graph
2025-11-15 15:59:32.0146 - INFO - graphrag.logger.progress - extract graph progress: 1/9
2025-11-15 15:59:32.0147 - INFO - graphrag.logger.progress - extract graph progress: 2/9
2025-11-15 15:59:32.0148 - INFO - graphrag.logger.progress - extract graph progress: 3/9
2025-11-15 15:59:32.0149 - INFO - graphrag.logger.progress - extract graph progress: 4/9
2025-11-15 15:59:35.0021 - INFO - graphrag.logger.progress - extract graph progress: 5/9
2025-11-15 15:59:35.0022 - INFO - graphrag.logger.progress - extract graph progress: 6/9
2025-11-15 15:59:36.0453 - INFO - graphrag.logger.progress - extract graph progress: 7/9
2025-11-15 15:59:36.0590 - INFO - graphrag.logger.progress - extract graph progress: 8/9
2025-11-15 15:59:36.0590 - INFO - graphrag.logger.progress - extract graph progress: 9/9
2025-11-15 15:59:36.0608 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/summarize_descriptions
2025-11-15 15:59:36.0608 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 1/362
2025-11-15 15:59:36.0608 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 2/362
2025-11-15 15:59:36.0608 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 3/362
2025-11-15 15:59:36.0610 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 4/362
2025-11-15 15:59:36.0610 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 5/362
2025-11-15 15:59:36.0610 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 6/362
2025-11-15 15:59:36.0610 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 7/362
2025-11-15 15:59:36.0611 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 8/362
2025-11-15 15:59:36.0611 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 9/362
2025-11-15 15:59:36.0612 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 10/362
2025-11-15 15:59:36.0612 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 11/362
2025-11-15 15:59:36.0612 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 12/362
2025-11-15 15:59:36.0612 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 13/362
2025-11-15 15:59:36.0612 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 14/362
2025-11-15 15:59:36.0613 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 15/362
2025-11-15 15:59:36.0613 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 16/362
2025-11-15 15:59:36.0613 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 17/362
2025-11-15 15:59:36.0614 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 18/362
2025-11-15 15:59:36.0614 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 19/362
2025-11-15 15:59:36.0614 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 20/362
2025-11-15 15:59:36.0614 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 21/362
2025-11-15 15:59:36.0614 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 22/362
2025-11-15 15:59:36.0614 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 23/362
2025-11-15 15:59:36.0614 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 24/362
2025-11-15 15:59:36.0614 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 25/362
2025-11-15 15:59:36.0614 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 26/362
2025-11-15 15:59:37.0307 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342420761s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342420761s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342420761s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

2025-11-15 15:59:37.0308 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342191148s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342191148s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342191148s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

2025-11-15 15:59:37.0310 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342366028s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342366028s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342366028s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

2025-11-15 15:59:37.0311 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.34212212s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.34212212s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.34212212s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

2025-11-15 15:59:37.0312 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.34219806s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.34219806s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.34219806s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

2025-11-15 15:59:37.0312 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342110691s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342110691s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342110691s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

2025-11-15 15:59:37.0313 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342217321s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342217321s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342217321s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

2025-11-15 15:59:37.0314 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.341735457s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.341735457s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.341735457s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

2025-11-15 15:59:37.0315 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342397134s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342397134s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342397134s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

2025-11-15 15:59:37.0316 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.34200026s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.34200026s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.34200026s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

2025-11-15 15:59:37.0316 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342166154s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342166154s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342166154s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

2025-11-15 15:59:37.0317 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.34214152s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.34214152s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.34214152s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

2025-11-15 15:59:37.0318 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342118639s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342118639s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342118639s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

2025-11-15 15:59:37.0319 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342116961s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342116961s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342116961s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

2025-11-15 15:59:37.0320 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342161889s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342161889s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.342161889s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

2025-11-15 15:59:37.0339 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 27/362
2025-11-15 15:59:37.0419 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.225939293s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.225939293s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.225939293s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

2025-11-15 15:59:37.0734 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 28/362
2025-11-15 15:59:37.0820 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.805050907s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.805050907s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.805050907s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}

2025-11-15 15:59:37.0878 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 29/362
2025-11-15 15:59:37.0985 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.638755564s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.638755564s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.638755564s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}

2025-11-15 15:59:38.0009 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 30/362
2025-11-15 15:59:38.0010 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 31/362
2025-11-15 15:59:38.0010 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 32/362
2025-11-15 15:59:38.0011 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 33/362
2025-11-15 15:59:38.0012 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 34/362
2025-11-15 15:59:38.0099 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.514664903s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.514664903s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.514664903s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}

2025-11-15 15:59:38.0103 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.51207366s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.51207366s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.51207366s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}

2025-11-15 15:59:38.0108 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.508085621s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.508085621s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.508085621s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}

2025-11-15 15:59:38.0120 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 35/362
2025-11-15 15:59:38.0121 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.493376994s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.493376994s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.493376994s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}

2025-11-15 15:59:38.0121 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 36/362
2025-11-15 15:59:38.0122 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 37/362
2025-11-15 15:59:38.0122 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 38/362
2025-11-15 15:59:38.0122 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 39/362
2025-11-15 15:59:38.0200 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.407753783s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.407753783s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.407753783s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}

2025-11-15 15:59:38.0205 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.401271027s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.401271027s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.401271027s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}

2025-11-15 15:59:38.0237 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 40/362
2025-11-15 15:59:38.0237 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 41/362
2025-11-15 15:59:38.0321 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.285383905s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.285383905s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 21.285383905s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}

2025-11-15 15:59:39.0433 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 20.124461686s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "20s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 20.124461686s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "20s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 20.124461686s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "20s"
      }
    ]
  }
}

2025-11-15 15:59:39.0515 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 20.036316725s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "20s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 20.036316725s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "20s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 20.036316725s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "20s"
      }
    ]
  }
}

2025-11-15 15:59:39.0583 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.96630837s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.96630837s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.96630837s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

2025-11-15 15:59:39.0669 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.872693387s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.872693387s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.872693387s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

2025-11-15 15:59:39.0786 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.751334487s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.751334487s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.751334487s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

2025-11-15 15:59:39.0865 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.669666504s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.669666504s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.669666504s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

2025-11-15 15:59:39.0875 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.659292521s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.659292521s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.659292521s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

2025-11-15 15:59:39.0927 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.603785948s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.603785948s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.603785948s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

2025-11-15 15:59:40.0097 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.42470416s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.42470416s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.42470416s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

2025-11-15 15:59:40.0151 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.367988908s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.367988908s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.367988908s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

2025-11-15 15:59:40.0232 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.286825155s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.286825155s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.286825155s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

2025-11-15 15:59:40.0237 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.280883214s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.280883214s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.280883214s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

2025-11-15 15:59:40.0278 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.239359069s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.239359069s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.239359069s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

2025-11-15 15:59:40.0289 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.227422601s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.227422601s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.227422601s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

2025-11-15 15:59:40.0311 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.202418536s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.202418536s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.202418536s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

2025-11-15 15:59:40.0315 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.199563485s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.199563485s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.199563485s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

2025-11-15 15:59:40.0344 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.169040425s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.169040425s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.169040425s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

2025-11-15 15:59:40.0355 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.155009648s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.155009648s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.155009648s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

2025-11-15 15:59:40.0428 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.084760895s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.084760895s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 19.084760895s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

2025-11-15 15:59:40.0741 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 18.752322329s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "18s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 18.752322329s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "18s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 18.752322329s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "18s"
      }
    ]
  }
}

2025-11-15 15:59:40.0772 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 18.721497681s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "18s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 18.721497681s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "18s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 18.721497681s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "18s"
      }
    ]
  }
}

2025-11-15 15:59:40.0952 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 18.53221045s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "18s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 18.53221045s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "18s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 18.53221045s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "18s"
      }
    ]
  }
}

2025-11-15 15:59:40.0965 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 18.517485522s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "18s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 18.517485522s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "18s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 18.517485522s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "18s"
      }
    ]
  }
}

2025-11-15 15:59:40.0984 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 18.499558531s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "18s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 18.499558531s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "18s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 18.499558531s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "18s"
      }
    ]
  }
}

2025-11-15 15:59:41.0040 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 18.442808411s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "18s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 18.442808411s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "18s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 18.442808411s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "18s"
      }
    ]
  }
}

2025-11-15 15:59:43.0694 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 15.667765475s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "15s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 15.667765475s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "15s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 15.667765475s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "15s"
      }
    ]
  }
}

2025-11-15 15:59:43.0999 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 15.348973328s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "15s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 15.348973328s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "15s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 15.348973328s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "15s"
      }
    ]
  }
}

2025-11-15 15:59:44.0225 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 15.113305798s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "15s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 15.113305798s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "15s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 15.113305798s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "15s"
      }
    ]
  }
}

2025-11-15 15:59:44.0240 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 15.098095876s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "15s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 15.098095876s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "15s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 15.098095876s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "15s"
      }
    ]
  }
}

2025-11-15 15:59:44.0311 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 15.02447915s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "15s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 15.02447915s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "15s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 15.02447915s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "15s"
      }
    ]
  }
}

2025-11-15 15:59:44.0405 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.926233409s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.926233409s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.926233409s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}

2025-11-15 15:59:44.0530 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.793746384s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.793746384s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.793746384s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}

2025-11-15 15:59:44.0587 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.732493562s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.732493562s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.732493562s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}

2025-11-15 15:59:44.0706 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.611391645s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.611391645s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.611391645s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}

2025-11-15 15:59:44.0722 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.596011957s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.596011957s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.596011957s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}

2025-11-15 15:59:44.0749 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.566475839s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.566475839s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.566475839s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}

2025-11-15 15:59:44.0759 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.555093653s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.555093653s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.555093653s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}

2025-11-15 15:59:44.0945 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.363562868s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.363562868s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.363562868s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}

2025-11-15 15:59:45.0070 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.230182718s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.230182718s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.230182718s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}

2025-11-15 15:59:45.0118 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.179746033s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.179746033s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.179746033s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}

2025-11-15 15:59:45.0259 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.03443332s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.03443332s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.03443332s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}

2025-11-15 15:59:45.0282 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.009582579s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.009582579s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.009582579s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}

2025-11-15 15:59:45.0293 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.994660422s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.994660422s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.994660422s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 15:59:45.0296 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.990837449s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.990837449s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.990837449s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 15:59:45.0375 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.912467743s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.912467743s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.912467743s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 15:59:45.0444 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.840043142s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.840043142s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.840043142s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 15:59:45.0482 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.8013772s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.8013772s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.8013772s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 15:59:45.0512 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.768050733s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.768050733s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.768050733s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 15:59:45.0617 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.657165117s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.657165117s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.657165117s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 15:59:45.0765 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.50664776s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.50664776s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.50664776s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 15:59:52.0430 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 6.538319882s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "6s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 6.538319882s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "6s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 6.538319882s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "6s"
      }
    ]
  }
}

2025-11-15 15:59:52.0626 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 6.332898473s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "6s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 6.332898473s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "6s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 6.332898473s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "6s"
      }
    ]
  }
}

2025-11-15 15:59:52.0679 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 6.279923968s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "6s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 6.279923968s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "6s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 6.279923968s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "6s"
      }
    ]
  }
}

2025-11-15 15:59:52.0976 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.974393699s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.974393699s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.974393699s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}

2025-11-15 15:59:52.0996 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.94925182s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.94925182s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.94925182s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}

2025-11-15 15:59:53.0063 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.87711505s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.87711505s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.87711505s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}

2025-11-15 15:59:53.0142 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.793297247s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.793297247s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.793297247s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}

2025-11-15 15:59:53.0185 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.746345214s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.746345214s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.746345214s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}

2025-11-15 15:59:53.0316 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.612894734s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.612894734s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.612894734s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}

2025-11-15 15:59:53.0519 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.398336727s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.398336727s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.398336727s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}

2025-11-15 15:59:53.0569 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.348782527s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.348782527s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.348782527s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}

2025-11-15 15:59:53.0658 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.252398519s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.252398519s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.252398519s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}

2025-11-15 15:59:53.0680 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.229850153s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.229850153s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.229850153s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}

2025-11-15 15:59:53.0770 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.136756985s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.136756985s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.136756985s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}

2025-11-15 15:59:53.0786 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.121401366s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.121401366s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 5.121401366s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}

2025-11-15 15:59:53.0935 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.964906596s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.964906596s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.964906596s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}

2025-11-15 15:59:53.0974 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.921834958s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.921834958s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.921834958s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}

2025-11-15 15:59:54.0130 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.765459954s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.765459954s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.765459954s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}

2025-11-15 15:59:54.0137 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.753063916s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.753063916s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.753063916s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}

2025-11-15 15:59:54.0139 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.754476132s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.754476132s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.754476132s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}

2025-11-15 15:59:54.0151 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.739100245s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.739100245s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.739100245s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}

2025-11-15 15:59:54.0162 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.729573007s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.729573007s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.729573007s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}

2025-11-15 15:59:54.0184 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.703282613s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.703282613s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.703282613s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}

2025-11-15 15:59:54.0191 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.698952424s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.698952424s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.698952424s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}

2025-11-15 15:59:54.0302 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.582185215s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.582185215s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 4.582185215s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}

2025-11-15 16:00:11.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 42/362
2025-11-15 16:00:11.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 43/362
2025-11-15 16:00:11.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 44/362
2025-11-15 16:00:11.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 45/362
2025-11-15 16:00:11.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 46/362
2025-11-15 16:00:11.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 47/362
2025-11-15 16:00:11.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 48/362
2025-11-15 16:00:11.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 49/362
2025-11-15 16:00:11.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 50/362
2025-11-15 16:00:11.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 51/362
2025-11-15 16:00:11.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 52/362
2025-11-15 16:00:11.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 53/362
2025-11-15 16:00:11.0461 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 54/362
2025-11-15 16:00:11.0461 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 55/362
2025-11-15 16:00:11.0461 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 56/362
2025-11-15 16:00:11.0461 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 57/362
2025-11-15 16:00:11.0461 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 58/362
2025-11-15 16:00:11.0461 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 59/362
2025-11-15 16:00:11.0461 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 60/362
2025-11-15 16:00:11.0461 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 61/362
2025-11-15 16:00:11.0461 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 62/362
2025-11-15 16:00:11.0461 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 63/362
2025-11-15 16:00:11.0461 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 64/362
2025-11-15 16:00:11.0496 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 65/362
2025-11-15 16:00:11.0496 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 66/362
2025-11-15 16:00:11.0496 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 67/362
2025-11-15 16:00:11.0496 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 68/362
2025-11-15 16:00:11.0496 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 69/362
2025-11-15 16:00:11.0522 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 70/362
2025-11-15 16:00:11.0522 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 71/362
2025-11-15 16:00:11.0522 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 72/362
2025-11-15 16:00:11.0522 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 73/362
2025-11-15 16:00:11.0522 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 74/362
2025-11-15 16:00:11.0522 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 75/362
2025-11-15 16:00:11.0523 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 76/362
2025-11-15 16:00:11.0523 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 77/362
2025-11-15 16:00:11.0523 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 78/362
2025-11-15 16:00:11.0523 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 79/362
2025-11-15 16:00:11.0523 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 80/362
2025-11-15 16:00:11.0523 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 81/362
2025-11-15 16:00:11.0523 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 82/362
2025-11-15 16:00:11.0523 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 83/362
2025-11-15 16:00:11.0523 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 84/362
2025-11-15 16:00:11.0523 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 85/362
2025-11-15 16:00:11.0523 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 86/362
2025-11-15 16:00:11.0523 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 87/362
2025-11-15 16:00:11.0762 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 88/362
2025-11-15 16:00:11.0762 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 89/362
2025-11-15 16:00:11.0762 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 90/362
2025-11-15 16:00:11.0762 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 91/362
2025-11-15 16:00:11.0762 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 92/362
2025-11-15 16:00:11.0762 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 93/362
2025-11-15 16:00:11.0762 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 94/362
2025-11-15 16:00:11.0762 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 95/362
2025-11-15 16:00:11.0762 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 96/362
2025-11-15 16:00:11.0762 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 97/362
2025-11-15 16:00:11.0762 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 98/362
2025-11-15 16:00:11.0762 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 99/362
2025-11-15 16:00:11.0762 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 100/362
2025-11-15 16:00:11.0762 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 101/362
2025-11-15 16:00:11.0762 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 102/362
2025-11-15 16:00:11.0762 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 103/362
2025-11-15 16:00:11.0763 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 104/362
2025-11-15 16:00:11.0763 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 105/362
2025-11-15 16:00:11.0763 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 106/362
2025-11-15 16:00:11.0763 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 107/362
2025-11-15 16:00:11.0763 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 108/362
2025-11-15 16:00:11.0763 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 109/362
2025-11-15 16:00:11.0763 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 110/362
2025-11-15 16:00:11.0763 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 111/362
2025-11-15 16:00:11.0763 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 112/362
2025-11-15 16:00:11.0924 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 113/362
2025-11-15 16:00:11.0924 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 114/362
2025-11-15 16:00:12.0066 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.533074472s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.533074472s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.533074472s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}

2025-11-15 16:00:12.0067 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.532807345s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.532807345s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.532807345s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}

2025-11-15 16:00:12.0068 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.532735262s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.532735262s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.532735262s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}

2025-11-15 16:00:12.0069 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.532546195s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.532546195s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.532546195s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}

2025-11-15 16:00:12.0070 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.532869827s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.532869827s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.532869827s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}

2025-11-15 16:00:12.0071 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.532912991s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.532912991s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.532912991s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}

2025-11-15 16:00:12.0072 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.532684947s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.532684947s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.532684947s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}

2025-11-15 16:00:12.0073 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: GeminiException - {
  "error": {
    "code": 429,
    "message": "Resource has been exhausted (e.g. check quota).",
    "status": "RESOURCE_EXHAUSTED"
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "Resource has been exhausted (e.g. check quota).",
    "status": "RESOURCE_EXHAUSTED"
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1345, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: GeminiException - {
  "error": {
    "code": 429,
    "message": "Resource has been exhausted (e.g. check quota).",
    "status": "RESOURCE_EXHAUSTED"
  }
}

2025-11-15 16:00:12.0083 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 115/362
2025-11-15 16:00:12.0083 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 116/362
2025-11-15 16:00:12.0094 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.505428058s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.505428058s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.505428058s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}

2025-11-15 16:00:12.0205 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.389807226s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.389807226s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.389807226s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}

2025-11-15 16:00:12.0216 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 117/362
2025-11-15 16:00:12.0393 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.192748503s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.192748503s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.192748503s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}

2025-11-15 16:00:12.0409 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 118/362
2025-11-15 16:00:12.0438 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 119/362
2025-11-15 16:00:12.0560 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.019444556s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.019444556s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 47.019444556s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "47s"
      }
    ]
  }
}

2025-11-15 16:00:12.0600 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 120/362
2025-11-15 16:00:12.0663 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 46.911919333s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "46s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 46.911919333s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "46s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 46.911919333s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "46s"
      }
    ]
  }
}

2025-11-15 16:00:12.0665 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 46.90607155s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "46s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 46.90607155s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "46s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 46.90607155s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "46s"
      }
    ]
  }
}

2025-11-15 16:00:12.0774 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 121/362
2025-11-15 16:00:12.0774 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 122/362
2025-11-15 16:00:14.0986 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.482093928s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.482093928s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.482093928s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}

2025-11-15 16:00:19.0366 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 39.956181639s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "39s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 39.956181639s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "39s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 39.956181639s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "39s"
      }
    ]
  }
}

2025-11-15 16:00:27.0699 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 31.197004432s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "31s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 31.197004432s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "31s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 31.197004432s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "31s"
      }
    ]
  }
}

2025-11-15 16:00:45.0432 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.183973127s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.183973127s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 14.183973127s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "14s"
      }
    ]
  }
}

2025-11-15 16:00:45.0608 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.996501316s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.996501316s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.996501316s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 16:00:45.0811 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.78520896s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.78520896s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.78520896s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 16:00:45.0819 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.778577414s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.778577414s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.778577414s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 16:00:46.0080 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.502751789s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.502751789s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.502751789s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 16:00:46.0081 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.502123566s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.502123566s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.502123566s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 16:00:46.0218 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.360312168s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.360312168s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.360312168s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 16:00:46.0381 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.194239318s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.194239318s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.194239318s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 16:00:46.0433 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.135879843s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.135879843s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.135879843s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 16:00:46.0434 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.131037278s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.131037278s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.131037278s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 16:00:46.0505 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.061187236s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.061187236s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.061187236s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 16:00:46.0540 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.022781598s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.022781598s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.022781598s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 16:00:46.0665 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 12.894311747s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "12s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 12.894311747s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "12s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 12.894311747s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "12s"
      }
    ]
  }
}

2025-11-15 16:00:46.0680 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 12.876307043s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "12s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 12.876307043s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "12s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 12.876307043s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "12s"
      }
    ]
  }
}

2025-11-15 16:01:20.0223 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 123/362
2025-11-15 16:01:53.0827 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 124/362
2025-11-15 16:01:54.0034 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 125/362
2025-11-15 16:01:54.0377 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 126/362
2025-11-15 16:01:54.0509 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 127/362
2025-11-15 16:01:54.0530 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 128/362
2025-11-15 16:01:54.0641 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 129/362
2025-11-15 16:01:54.0739 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 130/362
2025-11-15 16:01:54.0792 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 131/362
2025-11-15 16:01:54.0793 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 132/362
2025-11-15 16:01:54.0848 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 133/362
2025-11-15 16:01:54.0949 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 134/362
2025-11-15 16:01:55.0313 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 135/362
2025-11-15 16:01:55.0402 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 136/362
2025-11-15 16:01:55.0403 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 137/362
2025-11-15 16:01:55.0403 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 138/362
2025-11-15 16:01:55.0403 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 139/362
2025-11-15 16:01:55.0403 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 140/362
2025-11-15 16:01:55.0403 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 141/362
2025-11-15 16:01:55.0404 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 142/362
2025-11-15 16:01:55.0404 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 143/362
2025-11-15 16:01:55.0404 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 144/362
2025-11-15 16:01:55.0404 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 145/362
2025-11-15 16:01:55.0404 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 146/362
2025-11-15 16:01:55.0404 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 147/362
2025-11-15 16:01:55.0404 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 148/362
2025-11-15 16:01:55.0404 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 149/362
2025-11-15 16:01:55.0404 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 150/362
2025-11-15 16:01:55.0404 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 151/362
2025-11-15 16:01:55.0404 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 152/362
2025-11-15 16:01:55.0404 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 153/362
2025-11-15 16:01:55.0404 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 154/362
2025-11-15 16:01:55.0404 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 155/362
2025-11-15 16:01:55.0404 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 156/362
2025-11-15 16:01:55.0404 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 157/362
2025-11-15 16:01:55.0405 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 158/362
2025-11-15 16:01:55.0405 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 159/362
2025-11-15 16:01:55.0405 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 160/362
2025-11-15 16:01:55.0405 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 161/362
2025-11-15 16:01:55.0405 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 162/362
2025-11-15 16:01:55.0405 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 163/362
2025-11-15 16:01:55.0405 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 164/362
2025-11-15 16:01:55.0405 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 165/362
2025-11-15 16:01:55.0405 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 166/362
2025-11-15 16:01:55.0405 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 167/362
2025-11-15 16:01:55.0405 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 168/362
2025-11-15 16:01:55.0405 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 169/362
2025-11-15 16:01:55.0405 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 170/362
2025-11-15 16:01:55.0405 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 171/362
2025-11-15 16:01:55.0405 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 172/362
2025-11-15 16:01:55.0406 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 173/362
2025-11-15 16:01:55.0406 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 174/362
2025-11-15 16:01:55.0406 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 175/362
2025-11-15 16:01:55.0406 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 176/362
2025-11-15 16:01:55.0406 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 177/362
2025-11-15 16:01:55.0406 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 178/362
2025-11-15 16:01:55.0406 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 179/362
2025-11-15 16:01:55.0406 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 180/362
2025-11-15 16:01:55.0406 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 181/362
2025-11-15 16:01:55.0406 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 182/362
2025-11-15 16:01:55.0406 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 183/362
2025-11-15 16:01:55.0406 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 184/362
2025-11-15 16:01:55.0406 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 185/362
2025-11-15 16:01:55.0406 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 186/362
2025-11-15 16:01:55.0406 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 187/362
2025-11-15 16:01:55.0406 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 188/362
2025-11-15 16:01:55.0406 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 189/362
2025-11-15 16:01:55.0406 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 190/362
2025-11-15 16:01:55.0407 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 191/362
2025-11-15 16:01:55.0407 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 192/362
2025-11-15 16:01:55.0407 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 193/362
2025-11-15 16:01:55.0407 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 194/362
2025-11-15 16:01:55.0407 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 195/362
2025-11-15 16:01:55.0407 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 196/362
2025-11-15 16:01:55.0407 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 197/362
2025-11-15 16:01:55.0407 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 198/362
2025-11-15 16:01:55.0407 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 199/362
2025-11-15 16:01:55.0407 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 200/362
2025-11-15 16:01:55.0407 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 201/362
2025-11-15 16:01:55.0407 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 202/362
2025-11-15 16:01:55.0407 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 203/362
2025-11-15 16:01:55.0407 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 204/362
2025-11-15 16:01:55.0407 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 205/362
2025-11-15 16:01:55.0407 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 206/362
2025-11-15 16:01:55.0408 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 207/362
2025-11-15 16:01:55.0408 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 208/362
2025-11-15 16:01:55.0408 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 209/362
2025-11-15 16:01:55.0408 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 210/362
2025-11-15 16:01:55.0408 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 211/362
2025-11-15 16:01:55.0408 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 212/362
2025-11-15 16:01:55.0409 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 213/362
2025-11-15 16:01:55.0409 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 214/362
2025-11-15 16:01:55.0409 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 215/362
2025-11-15 16:01:55.0409 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 216/362
2025-11-15 16:01:55.0409 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 217/362
2025-11-15 16:01:55.0409 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 218/362
2025-11-15 16:01:55.0409 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 219/362
2025-11-15 16:01:55.0409 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 220/362
2025-11-15 16:01:55.0409 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 221/362
2025-11-15 16:01:55.0410 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 222/362
2025-11-15 16:01:55.0410 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 223/362
2025-11-15 16:01:55.0410 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 224/362
2025-11-15 16:01:55.0411 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 225/362
2025-11-15 16:01:55.0411 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 226/362
2025-11-15 16:01:55.0411 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 227/362
2025-11-15 16:01:55.0412 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 228/362
2025-11-15 16:01:55.0412 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 229/362
2025-11-15 16:01:55.0412 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 230/362
2025-11-15 16:01:55.0412 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 231/362
2025-11-15 16:01:55.0412 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 232/362
2025-11-15 16:01:55.0412 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 233/362
2025-11-15 16:01:55.0412 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 234/362
2025-11-15 16:01:55.0412 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 235/362
2025-11-15 16:01:55.0412 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 236/362
2025-11-15 16:01:55.0412 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 237/362
2025-11-15 16:01:55.0412 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 238/362
2025-11-15 16:01:55.0413 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 239/362
2025-11-15 16:01:55.0413 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 240/362
2025-11-15 16:01:55.0413 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 241/362
2025-11-15 16:01:55.0413 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 242/362
2025-11-15 16:01:55.0413 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 243/362
2025-11-15 16:01:55.0413 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 244/362
2025-11-15 16:01:55.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 245/362
2025-11-15 16:01:55.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 246/362
2025-11-15 16:01:55.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 247/362
2025-11-15 16:01:55.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 248/362
2025-11-15 16:01:55.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 249/362
2025-11-15 16:01:55.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 250/362
2025-11-15 16:01:55.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 251/362
2025-11-15 16:01:55.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 252/362
2025-11-15 16:01:55.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 253/362
2025-11-15 16:01:55.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 254/362
2025-11-15 16:01:55.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 255/362
2025-11-15 16:01:55.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 256/362
2025-11-15 16:01:55.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 257/362
2025-11-15 16:01:55.0414 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 258/362
2025-11-15 16:01:55.0415 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 259/362
2025-11-15 16:01:55.0415 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 260/362
2025-11-15 16:01:55.0415 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 261/362
2025-11-15 16:01:55.0415 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 262/362
2025-11-15 16:01:55.0415 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 263/362
2025-11-15 16:01:55.0415 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 264/362
2025-11-15 16:01:55.0415 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 265/362
2025-11-15 16:01:55.0415 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 266/362
2025-11-15 16:01:55.0415 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 267/362
2025-11-15 16:01:55.0415 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 268/362
2025-11-15 16:01:55.0415 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 269/362
2025-11-15 16:01:55.0415 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 270/362
2025-11-15 16:01:55.0415 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 271/362
2025-11-15 16:01:55.0416 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 272/362
2025-11-15 16:01:55.0416 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 273/362
2025-11-15 16:01:55.0416 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 274/362
2025-11-15 16:01:55.0416 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 275/362
2025-11-15 16:01:55.0416 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 276/362
2025-11-15 16:01:55.0416 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 277/362
2025-11-15 16:01:55.0416 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 278/362
2025-11-15 16:01:55.0416 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 279/362
2025-11-15 16:01:55.0417 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 280/362
2025-11-15 16:01:55.0417 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 281/362
2025-11-15 16:01:55.0417 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 282/362
2025-11-15 16:01:55.0417 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 283/362
2025-11-15 16:01:55.0417 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 284/362
2025-11-15 16:01:55.0417 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 285/362
2025-11-15 16:01:55.0417 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 286/362
2025-11-15 16:01:55.0417 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 287/362
2025-11-15 16:01:55.0417 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 288/362
2025-11-15 16:01:55.0417 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 289/362
2025-11-15 16:01:55.0417 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 290/362
2025-11-15 16:01:55.0417 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 291/362
2025-11-15 16:01:55.0417 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 292/362
2025-11-15 16:01:55.0417 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 293/362
2025-11-15 16:01:55.0418 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 294/362
2025-11-15 16:01:55.0418 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 295/362
2025-11-15 16:01:55.0418 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 296/362
2025-11-15 16:01:55.0418 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 297/362
2025-11-15 16:01:55.0418 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 298/362
2025-11-15 16:01:55.0418 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 299/362
2025-11-15 16:01:55.0418 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 300/362
2025-11-15 16:01:55.0418 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 301/362
2025-11-15 16:01:55.0418 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 302/362
2025-11-15 16:01:55.0418 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 303/362
2025-11-15 16:01:55.0418 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 304/362
2025-11-15 16:01:55.0418 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 305/362
2025-11-15 16:01:55.0418 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 306/362
2025-11-15 16:01:55.0418 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 307/362
2025-11-15 16:01:55.0418 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 308/362
2025-11-15 16:01:55.0418 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 309/362
2025-11-15 16:01:55.0418 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 310/362
2025-11-15 16:01:55.0418 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 311/362
2025-11-15 16:01:55.0418 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 312/362
2025-11-15 16:01:55.0419 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 313/362
2025-11-15 16:01:55.0419 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 314/362
2025-11-15 16:01:55.0419 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 315/362
2025-11-15 16:01:55.0419 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 316/362
2025-11-15 16:01:55.0419 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 317/362
2025-11-15 16:01:55.0419 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 318/362
2025-11-15 16:01:55.0419 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 319/362
2025-11-15 16:01:55.0419 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 320/362
2025-11-15 16:01:55.0419 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 321/362
2025-11-15 16:01:55.0419 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 322/362
2025-11-15 16:01:55.0419 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 323/362
2025-11-15 16:01:55.0419 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 324/362
2025-11-15 16:01:55.0419 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 325/362
2025-11-15 16:01:55.0419 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 326/362
2025-11-15 16:01:55.0419 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 327/362
2025-11-15 16:01:55.0419 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 328/362
2025-11-15 16:01:55.0419 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 329/362
2025-11-15 16:01:55.0419 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 330/362
2025-11-15 16:01:55.0420 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 331/362
2025-11-15 16:01:55.0420 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 332/362
2025-11-15 16:01:55.0420 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 333/362
2025-11-15 16:01:55.0420 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 334/362
2025-11-15 16:01:55.0420 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 335/362
2025-11-15 16:01:55.0420 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 336/362
2025-11-15 16:01:55.0420 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 337/362
2025-11-15 16:01:55.0420 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 338/362
2025-11-15 16:01:55.0420 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 339/362
2025-11-15 16:01:55.0420 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 340/362
2025-11-15 16:01:55.0420 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 341/362
2025-11-15 16:01:55.0420 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 342/362
2025-11-15 16:01:55.0420 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 343/362
2025-11-15 16:01:55.0420 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 344/362
2025-11-15 16:01:55.0420 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 345/362
2025-11-15 16:01:55.0420 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 346/362
2025-11-15 16:01:55.0420 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 347/362
2025-11-15 16:01:55.0420 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 348/362
2025-11-15 16:01:55.0420 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 349/362
2025-11-15 16:01:55.0420 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 350/362
2025-11-15 16:01:55.0421 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 351/362
2025-11-15 16:01:55.0421 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 352/362
2025-11-15 16:01:55.0700 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 3.784790196s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 3.784790196s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 3.784790196s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}

2025-11-15 16:01:55.0702 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 3.784828746s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 3.784828746s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 3.784828746s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}

2025-11-15 16:01:55.0702 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 3.784900268s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 3.784900268s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 3.784900268s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}

2025-11-15 16:01:55.0703 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 3.785089517s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 3.785089517s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 3.785089517s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}

2025-11-15 16:01:55.0704 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 3.784821214s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 3.784821214s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 3.784821214s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}

2025-11-15 16:01:55.0705 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 3.784961449s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 3.784961449s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 3.784961449s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}

2025-11-15 16:01:55.0706 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 3.784522701s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 3.784522701s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 3.784522701s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}

2025-11-15 16:01:55.0707 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 3.784783432s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 3.784783432s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 3.784783432s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}

2025-11-15 16:01:56.0101 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 353/362
2025-11-15 16:01:56.0333 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 354/362
2025-11-15 16:01:57.0827 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 1.567815327s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "1s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 1.567815327s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "1s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 1.567815327s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "1s"
      }
    ]
  }
}

2025-11-15 16:01:57.0859 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 1.528551796s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "1s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 1.528551796s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "1s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 1.528551796s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "1s"
      }
    ]
  }
}

2025-11-15 16:01:57.0865 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 1.524947955s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "1s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 1.524947955s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "1s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 1.524947955s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "1s"
      }
    ]
  }
}

2025-11-15 16:01:58.0121 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 1.259660728s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "1s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 1.259660728s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "1s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 1.259660728s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "1s"
      }
    ]
  }
}

2025-11-15 16:01:58.0446 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 917.618256ms.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "0s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 917.618256ms.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "0s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 917.618256ms.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "0s"
      }
    ]
  }
}

2025-11-15 16:01:58.0470 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 890.129539ms.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "0s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 890.129539ms.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "0s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 890.129539ms.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "0s"
      }
    ]
  }
}

2025-11-15 16:01:58.0661 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 693.916658ms.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "0s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 693.916658ms.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "0s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 693.916658ms.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "0s"
      }
    ]
  }
}

2025-11-15 16:01:58.0763 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 583.282993ms.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "0s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 583.282993ms.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "0s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 583.282993ms.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "0s"
      }
    ]
  }
}

2025-11-15 16:02:02.0251 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 56.942162347s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "56s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 56.942162347s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "56s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 56.942162347s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "56s"
      }
    ]
  }
}

2025-11-15 16:02:02.0622 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 56.555494913s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "56s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 56.555494913s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "56s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 56.555494913s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "56s"
      }
    ]
  }
}

2025-11-15 16:02:02.0898 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 56.266847978s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "56s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 56.266847978s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "56s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 56.266847978s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "56s"
      }
    ]
  }
}

2025-11-15 16:02:03.0028 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 56.131441981s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "56s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 56.131441981s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "56s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 56.131441981s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "56s"
      }
    ]
  }
}

2025-11-15 16:02:03.0104 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 56.048455552s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "56s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 56.048455552s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "56s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 56.048455552s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "56s"
      }
    ]
  }
}

2025-11-15 16:02:03.0134 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 56.019320644s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "56s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 56.019320644s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "56s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 56.019320644s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "56s"
      }
    ]
  }
}

2025-11-15 16:02:03.0259 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 55.887564508s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "55s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 55.887564508s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "55s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 55.887564508s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "55s"
      }
    ]
  }
}

2025-11-15 16:02:03.0431 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 55.709076096s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "55s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 55.709076096s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "55s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 55.709076096s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "55s"
      }
    ]
  }
}

2025-11-15 16:02:11.0359 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 355/362
2025-11-15 16:02:11.0790 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 356/362
2025-11-15 16:02:12.0048 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 357/362
2025-11-15 16:02:12.0175 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 358/362
2025-11-15 16:02:12.0381 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 359/362
2025-11-15 16:02:12.0738 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 360/362
2025-11-15 16:02:12.0838 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 361/362
2025-11-15 16:02:12.0838 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 362/362
2025-11-15 16:02:12.0845 - INFO - graphrag.index.workflows.extract_graph - Workflow completed: extract_graph
2025-11-15 16:02:12.0845 - INFO - graphrag.api.index - Workflow extract_graph completed successfully
2025-11-15 16:02:12.0853 - INFO - graphrag.index.workflows.finalize_graph - Workflow started: finalize_graph
2025-11-15 16:02:12.0853 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-11-15 16:02:12.0856 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-11-15 16:02:12.0877 - INFO - graphrag.index.workflows.finalize_graph - Workflow completed: finalize_graph
2025-11-15 16:02:12.0877 - INFO - graphrag.api.index - Workflow finalize_graph completed successfully
2025-11-15 16:02:12.0886 - INFO - graphrag.index.workflows.extract_covariates - Workflow started: extract_covariates
2025-11-15 16:02:12.0886 - INFO - graphrag.index.workflows.extract_covariates - Workflow completed: extract_covariates
2025-11-15 16:02:12.0886 - INFO - graphrag.api.index - Workflow extract_covariates completed successfully
2025-11-15 16:02:12.0886 - INFO - graphrag.index.workflows.create_communities - Workflow started: create_communities
2025-11-15 16:02:12.0886 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-11-15 16:02:12.0889 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-11-15 16:02:12.0920 - INFO - graphrag.index.workflows.create_communities - Workflow completed: create_communities
2025-11-15 16:02:12.0920 - INFO - graphrag.api.index - Workflow create_communities completed successfully
2025-11-15 16:02:12.0931 - INFO - graphrag.index.workflows.create_final_text_units - Workflow started: create_final_text_units
2025-11-15 16:02:12.0932 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 16:02:12.0934 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-11-15 16:02:12.0936 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-11-15 16:02:12.0951 - INFO - graphrag.index.workflows.create_final_text_units - Workflow completed: create_final_text_units
2025-11-15 16:02:12.0952 - INFO - graphrag.api.index - Workflow create_final_text_units completed successfully
2025-11-15 16:02:12.0957 - INFO - graphrag.index.workflows.create_community_reports - Workflow started: create_community_reports
2025-11-15 16:02:12.0957 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-11-15 16:02:12.0961 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-11-15 16:02:12.0963 - INFO - graphrag.utils.storage - reading table from storage: communities.parquet
2025-11-15 16:02:12.0970 - INFO - graphrag.index.operations.summarize_communities.graph_context.context_builder - Number of nodes at level=1 => 92
2025-11-15 16:02:13.0038 - INFO - graphrag.index.operations.summarize_communities.graph_context.context_builder - Number of nodes at level=0 => 114
2025-11-15 16:02:13.0138 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/community_reporting
2025-11-15 16:02:13.0850 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817539044s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817539044s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817539044s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}

2025-11-15 16:02:13.0851 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.816794131s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.816794131s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.816794131s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}

2025-11-15 16:02:13.0852 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.8174276s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.8174276s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.8174276s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}

2025-11-15 16:02:13.0853 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817701719s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817701719s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817701719s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}

2025-11-15 16:02:13.0854 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817718503s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817718503s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817718503s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}

2025-11-15 16:02:13.0854 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817469028s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817469028s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817469028s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}

2025-11-15 16:02:13.0855 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817471389s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817471389s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817471389s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}

2025-11-15 16:02:13.0856 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817539851s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817539851s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817539851s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}

2025-11-15 16:02:13.0857 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817789938s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817789938s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817789938s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}

2025-11-15 16:02:13.0858 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.816614118s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.816614118s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.816614118s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}

2025-11-15 16:02:13.0858 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817186006s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817186006s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817186006s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}

2025-11-15 16:02:13.0859 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817456598s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817456598s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 44.817456598s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}

2025-11-15 16:02:15.0970 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 42.604961571s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "42s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 42.604961571s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "42s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 42.604961571s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "42s"
      }
    ]
  }
}

2025-11-15 16:02:16.0052 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 42.519268753s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "42s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 42.519268753s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "42s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 42.519268753s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "42s"
      }
    ]
  }
}

2025-11-15 16:02:17.0535 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 42.481346362s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "42s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 42.481346362s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "42s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 42.481346362s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "42s"
      }
    ]
  }
}

2025-11-15 16:02:17.0597 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 1/20
2025-11-15 16:02:17.0814 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 42.190361648s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "42s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 42.190361648s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "42s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 42.190361648s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "42s"
      }
    ]
  }
}

2025-11-15 16:02:17.0863 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 42.141226871s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "42s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 42.141226871s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "42s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 42.141226871s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "42s"
      }
    ]
  }
}

2025-11-15 16:02:17.0939 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 42.06116146s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "42s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 42.06116146s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "42s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 42.06116146s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "42s"
      }
    ]
  }
}

2025-11-15 16:02:18.0080 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 2/20
2025-11-15 16:02:18.0183 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 3/20
2025-11-15 16:02:18.0209 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 41.778527127s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "41s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 41.778527127s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "41s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 41.778527127s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "41s"
      }
    ]
  }
}

2025-11-15 16:02:18.0215 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 41.770671206s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "41s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 41.770671206s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "41s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 41.770671206s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "41s"
      }
    ]
  }
}

2025-11-15 16:02:18.0236 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 41.746432913s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "41s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 41.746432913s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "41s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 41.746432913s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "41s"
      }
    ]
  }
}

2025-11-15 16:02:18.0252 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 41.733214273s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "41s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 41.733214273s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "41s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 41.733214273s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "41s"
      }
    ]
  }
}

2025-11-15 16:02:18.0293 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 41.689468988s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "41s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 41.689468988s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "41s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 41.689468988s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "41s"
      }
    ]
  }
}

2025-11-15 16:02:18.0338 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 41.646686992s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "41s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 41.646686992s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "41s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 41.646686992s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "41s"
      }
    ]
  }
}

2025-11-15 16:02:18.0654 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 4/20
2025-11-15 16:02:19.0284 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 5/20
2025-11-15 16:02:19.0415 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 6/20
2025-11-15 16:02:19.0649 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 7/20
2025-11-15 16:02:20.0002 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 8/20
2025-11-15 16:02:21.0849 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.97783794s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.97783794s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.97783794s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}

2025-11-15 16:02:21.0897 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.922353794s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.922353794s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.922353794s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}

2025-11-15 16:02:22.0325 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.478032505s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.478032505s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.478032505s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}

2025-11-15 16:02:22.0507 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.287384564s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.287384564s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.287384564s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}

2025-11-15 16:02:22.0540 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.252535733s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.252535733s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.252535733s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}

2025-11-15 16:02:22.0556 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.237769682s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.237769682s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.237769682s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}

2025-11-15 16:02:22.0720 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.066671481s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.066671481s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.066671481s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}

2025-11-15 16:02:22.0741 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.040256807s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.040256807s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 37.040256807s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "37s"
      }
    ]
  }
}

2025-11-15 16:02:22.0787 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 36.995825774s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "36s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 36.995825774s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "36s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 36.995825774s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "36s"
      }
    ]
  }
}

2025-11-15 16:02:22.0921 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 36.854656696s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "36s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 36.854656696s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "36s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 36.854656696s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "36s"
      }
    ]
  }
}

2025-11-15 16:02:23.0250 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 36.512969261s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "36s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 36.512969261s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "36s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 36.512969261s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "36s"
      }
    ]
  }
}

2025-11-15 16:02:23.0284 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 36.474209494s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "36s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 36.474209494s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "36s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 36.474209494s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "36s"
      }
    ]
  }
}

2025-11-15 16:02:29.0971 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 29.484116181s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 29.484116181s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 29.484116181s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}

2025-11-15 16:02:29.0985 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 29.470647071s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 29.470647071s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 29.470647071s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}

2025-11-15 16:02:30.0976 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 28.437774703s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 28.437774703s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 28.437774703s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}

2025-11-15 16:02:31.0175 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 28.228105493s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 28.228105493s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 28.228105493s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}

2025-11-15 16:02:31.0187 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 28.21652172s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 28.21652172s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 28.21652172s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}

2025-11-15 16:02:31.0228 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 28.173860685s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 28.173860685s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 28.173860685s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}

2025-11-15 16:02:31.0391 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 28.002704593s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 28.002704593s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 28.002704593s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}

2025-11-15 16:02:31.0477 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 27.911590042s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 27.911590042s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 27.911590042s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}

2025-11-15 16:02:31.0598 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 27.78522232s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 27.78522232s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 27.78522232s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}

2025-11-15 16:02:31.0725 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 27.652360931s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 27.652360931s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 27.652360931s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}

2025-11-15 16:02:31.0952 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 27.418448663s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 27.418448663s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 27.418448663s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}

2025-11-15 16:02:32.0360 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 26.988953478s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 26.988953478s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 26.988953478s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}

2025-11-15 16:02:46.0393 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 12.32118391s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "12s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 12.32118391s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "12s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 12.32118391s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "12s"
      }
    ]
  }
}

2025-11-15 16:02:46.0538 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 12.169308293s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "12s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 12.169308293s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "12s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 12.169308293s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "12s"
      }
    ]
  }
}

2025-11-15 16:02:47.0510 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 11.157056133s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "11s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 11.157056133s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "11s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 11.157056133s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "11s"
      }
    ]
  }
}

2025-11-15 16:02:47.0534 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 11.13397428s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "11s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 11.13397428s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "11s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 11.13397428s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "11s"
      }
    ]
  }
}

2025-11-15 16:02:47.0870 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 10.780617155s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "10s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 10.780617155s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "10s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 10.780617155s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "10s"
      }
    ]
  }
}

2025-11-15 16:02:47.0900 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 10.748183267s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "10s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 10.748183267s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "10s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 10.748183267s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "10s"
      }
    ]
  }
}

2025-11-15 16:02:47.0942 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 10.704795913s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "10s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 10.704795913s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "10s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 10.704795913s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "10s"
      }
    ]
  }
}

2025-11-15 16:02:48.0233 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.BadRequestError: GeminiException BadRequestError - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 10.403056995s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "10s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 10.403056995s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "10s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1227, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GeminiException BadRequestError - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 10.403056995s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "10s"
      }
    ]
  }
}

2025-11-15 16:02:48.0234 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 10.402489709s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "10s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 10.402489709s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "10s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 10.402489709s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "10s"
      }
    ]
  }
}

2025-11-15 16:02:48.0324 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 10.305972208s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "10s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 10.305972208s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "10s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 10.305972208s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "10s"
      }
    ]
  }
}

2025-11-15 16:02:48.0593 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 10.027833847s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "10s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 10.027833847s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "10s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 10.027833847s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "10s"
      }
    ]
  }
}

2025-11-15 16:02:49.0019 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 9.585391908s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "9s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 9.585391908s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "9s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 9.585391908s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "9s"
      }
    ]
  }
}

2025-11-15 16:03:25.0660 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 9/20
2025-11-15 16:03:26.0064 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 10/20
2025-11-15 16:03:26.0182 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 11/20
2025-11-15 16:03:26.0514 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 12/20
2025-11-15 16:03:26.0836 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 13/20
2025-11-15 16:03:27.0057 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 14/20
2025-11-15 16:03:27.0172 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 15/20
2025-11-15 16:03:27.0583 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 16/20
2025-11-15 16:03:27.0791 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 17/20
2025-11-15 16:03:28.0506 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 18/20
2025-11-15 16:03:28.0746 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 19/20
2025-11-15 16:03:29.0392 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 20/20
2025-11-15 16:03:30.0085 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 29.744335986s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 29.744335986s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 29.744335986s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}

2025-11-15 16:03:30.0086 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 29.743984587s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 29.743984587s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 29.743984587s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}

2025-11-15 16:03:30.0087 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 29.744330083s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 29.744330083s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 29.744330083s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}

2025-11-15 16:03:30.0088 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 29.743227771s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 29.743227771s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 29.743227771s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}

2025-11-15 16:03:30.0089 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 29.744357132s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 29.744357132s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 29.744357132s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}

2025-11-15 16:03:32.0439 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 27.291757766s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 27.291757766s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 27.291757766s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}

2025-11-15 16:03:32.0750 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 26.963735179s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 26.963735179s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 26.963735179s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}

2025-11-15 16:03:32.0877 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 26.827769827s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 26.827769827s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 26.827769827s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}

2025-11-15 16:03:32.0888 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 26.815956641s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 26.815956641s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 26.815956641s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}

2025-11-15 16:03:33.0114 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 26.58172238s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 26.58172238s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 26.58172238s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}

2025-11-15 16:03:33.0201 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 1/9
2025-11-15 16:03:33.0689 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 2/9
2025-11-15 16:03:35.0100 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 3/9
2025-11-15 16:03:35.0318 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 4/9
2025-11-15 16:03:37.0086 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.433711917s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.433711917s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.433711917s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

2025-11-15 16:03:37.0153 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.363076579s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.363076579s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.363076579s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

2025-11-15 16:03:37.0282 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.226077577s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.226077577s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.226077577s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

2025-11-15 16:03:37.0344 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.166731106s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.166731106s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.166731106s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

2025-11-15 16:03:37.0347 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.156003189s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.156003189s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 22.156003189s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

2025-11-15 16:03:45.0391 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.755530455s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.755530455s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.755530455s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 16:03:45.0738 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.391295174s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.391295174s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.391295174s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 16:03:45.0768 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.358788983s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.358788983s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.358788983s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 16:03:45.0996 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.121398427s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.121398427s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 13.121398427s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "13s"
      }
    ]
  }
}

2025-11-15 16:03:46.0367 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 12.735432168s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "12s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 12.735432168s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "12s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 12.735432168s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "12s"
      }
    ]
  }
}

2025-11-15 16:04:03.0480 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 56.350261364s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "56s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 56.350261364s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "56s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 56.350261364s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "56s"
      }
    ]
  }
}

2025-11-15 16:04:03.0913 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 55.909570933s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "55s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 55.909570933s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "55s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 55.909570933s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-2.5-flash-lite",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "55s"
      }
    ]
  }
}

2025-11-15 16:04:03.0987 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 55.827911176s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "55s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 55.827911176s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "55s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 55.827911176s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "55s"
      }
    ]
  }
}

2025-11-15 16:04:04.0261 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 55.544962352s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "55s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 55.544962352s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "55s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 55.544962352s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "55s"
      }
    ]
  }
}

2025-11-15 16:04:04.0585 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 55.209240448s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "55s"
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2031, in async_completion
    response = await client.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 595, in acompletion
    response = await init_response
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 2037, in async_completion
    raise VertexAIError(
litellm.llms.vertex_ai.common_utils.VertexAIError: {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 55.209240448s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "55s"
      }
    ]
  }
}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 614, in acompletion
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\nPlease retry in 55.209240448s.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-2.5-flash-lite"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "55s"
      }
    ]
  }
}

2025-11-15 16:04:42.0048 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 5/9
2025-11-15 16:04:42.0082 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 6/9
2025-11-15 16:04:43.0033 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 7/9
2025-11-15 16:04:44.0375 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 8/9
2025-11-15 16:04:45.0741 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 9/9
2025-11-15 16:04:45.0758 - INFO - graphrag.index.workflows.create_community_reports - Workflow completed: create_community_reports
2025-11-15 16:04:45.0759 - INFO - graphrag.api.index - Workflow create_community_reports completed successfully
2025-11-15 16:04:45.0786 - INFO - graphrag.index.workflows.generate_text_embeddings - Workflow started: generate_text_embeddings
2025-11-15 16:04:45.0786 - INFO - graphrag.index.workflows.generate_text_embeddings - Embedding the following fields: ['entity.description', 'community.full_content', 'text_unit.text']
2025-11-15 16:04:45.0786 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-11-15 16:04:45.0791 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-11-15 16:04:45.0795 - INFO - graphrag.utils.storage - reading table from storage: community_reports.parquet
2025-11-15 16:04:45.0809 - INFO - graphrag.index.workflows.generate_text_embeddings - Creating embeddings
2025-11-15 16:04:45.0809 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding entity.description: default-entity-description
2025-11-15 16:04:45.0849 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/1 of size 500 to vector store
2025-11-15 16:04:45.0850 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/granite/adk_test/generated_text_docs/cache/text_embedding
2025-11-15 16:04:45.0857 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 125 inputs via 125 snippets using 8 batches. max_batch_size=16, batch_max_tokens=8191
2025-11-15 16:04:47.0731 - INFO - graphrag.logger.progress - generate embeddings progress: 1/8
2025-11-15 16:04:47.0923 - INFO - graphrag.logger.progress - generate embeddings progress: 2/8
2025-11-15 16:04:48.0102 - INFO - graphrag.logger.progress - generate embeddings progress: 3/8
2025-11-15 16:04:48.0246 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/embed_content_free_tier_requests",
            "quotaId": "EmbedContentRequestsPerMinutePerUserPerProjectPerModel-FreeTier"
          }
        ]
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 3879, in aembedding
    response = await init_response  # type: ignore
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini_embeddings/batch_embed_content_handler.py", line 164, in async_batch_embeddings
    response = await async_handler.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-001:batchEmbedContents?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 95, in _base_aembedding
    return await aembedding(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 3894, in aembedding
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/embed_content_free_tier_requests",
            "quotaId": "EmbedContentRequestsPerMinutePerUserPerProjectPerModel-FreeTier"
          }
        ]
      }
    ]
  }
}

2025-11-15 16:04:48.0250 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/embed_content_free_tier_requests",
            "quotaId": "EmbedContentRequestsPerMinutePerUserPerProjectPerModel-FreeTier"
          }
        ]
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 3879, in aembedding
    response = await init_response  # type: ignore
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini_embeddings/batch_embed_content_handler.py", line 164, in async_batch_embeddings
    response = await async_handler.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-001:batchEmbedContents?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 95, in _base_aembedding
    return await aembedding(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 3894, in aembedding
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/embed_content_free_tier_requests",
            "quotaId": "EmbedContentRequestsPerMinutePerUserPerProjectPerModel-FreeTier"
          }
        ]
      }
    ]
  }
}

2025-11-15 16:04:48.0297 - INFO - graphrag.logger.progress - generate embeddings progress: 4/8
2025-11-15 16:04:48.0540 - INFO - graphrag.logger.progress - generate embeddings progress: 5/8
2025-11-15 16:04:49.0350 - INFO - graphrag.logger.progress - generate embeddings progress: 6/8
2025-11-15 16:04:50.0591 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/embed_content_free_tier_requests",
            "quotaId": "EmbedContentRequestsPerMinutePerUserPerProjectPerModel-FreeTier"
          }
        ]
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 3879, in aembedding
    response = await init_response  # type: ignore
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini_embeddings/batch_embed_content_handler.py", line 164, in async_batch_embeddings
    response = await async_handler.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-001:batchEmbedContents?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 95, in _base_aembedding
    return await aembedding(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 3894, in aembedding
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/embed_content_free_tier_requests",
            "quotaId": "EmbedContentRequestsPerMinutePerUserPerProjectPerModel-FreeTier"
          }
        ]
      }
    ]
  }
}

2025-11-15 16:04:50.0774 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/embed_content_free_tier_requests",
            "quotaId": "EmbedContentRequestsPerMinutePerUserPerProjectPerModel-FreeTier"
          }
        ]
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 3879, in aembedding
    response = await init_response  # type: ignore
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini_embeddings/batch_embed_content_handler.py", line 164, in async_batch_embeddings
    response = await async_handler.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-001:batchEmbedContents?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 95, in _base_aembedding
    return await aembedding(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 3894, in aembedding
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/embed_content_free_tier_requests",
            "quotaId": "EmbedContentRequestsPerMinutePerUserPerProjectPerModel-FreeTier"
          }
        ]
      }
    ]
  }
}

2025-11-15 16:04:55.0175 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/embed_content_free_tier_requests",
            "quotaId": "EmbedContentRequestsPerMinutePerUserPerProjectPerModel-FreeTier"
          }
        ]
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 3879, in aembedding
    response = await init_response  # type: ignore
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini_embeddings/batch_embed_content_handler.py", line 164, in async_batch_embeddings
    response = await async_handler.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-001:batchEmbedContents?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 95, in _base_aembedding
    return await aembedding(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 3894, in aembedding
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/embed_content_free_tier_requests",
            "quotaId": "EmbedContentRequestsPerMinutePerUserPerProjectPerModel-FreeTier"
          }
        ]
      }
    ]
  }
}

2025-11-15 16:04:55.0575 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/embed_content_free_tier_requests",
            "quotaId": "EmbedContentRequestsPerMinutePerUserPerProjectPerModel-FreeTier"
          }
        ]
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 3879, in aembedding
    response = await init_response  # type: ignore
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini_embeddings/batch_embed_content_handler.py", line 164, in async_batch_embeddings
    response = await async_handler.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-001:batchEmbedContents?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 95, in _base_aembedding
    return await aembedding(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 3894, in aembedding
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/embed_content_free_tier_requests",
            "quotaId": "EmbedContentRequestsPerMinutePerUserPerProjectPerModel-FreeTier"
          }
        ]
      }
    ]
  }
}

2025-11-15 16:05:03.0777 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/embed_content_free_tier_requests",
            "quotaId": "EmbedContentRequestsPerMinutePerUserPerProjectPerModel-FreeTier"
          }
        ]
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 3879, in aembedding
    response = await init_response  # type: ignore
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini_embeddings/batch_embed_content_handler.py", line 164, in async_batch_embeddings
    response = await async_handler.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-001:batchEmbedContents?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 95, in _base_aembedding
    return await aembedding(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 3894, in aembedding
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/embed_content_free_tier_requests",
            "quotaId": "EmbedContentRequestsPerMinutePerUserPerProjectPerModel-FreeTier"
          }
        ]
      }
    ]
  }
}

2025-11-15 16:05:03.0863 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/embed_content_free_tier_requests",
            "quotaId": "EmbedContentRequestsPerMinutePerUserPerProjectPerModel-FreeTier"
          }
        ]
      }
    ]
  }
}
Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 3879, in aembedding
    response = await init_response  # type: ignore
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini_embeddings/batch_embed_content_handler.py", line 164, in async_batch_embeddings
    response = await async_handler.post(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 360, in post
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/llms/custom_httpx/http_handler.py", line 316, in post
    response.raise_for_status()
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-001:batchEmbedContents?key=AIzaSyDG7pfbhHjA-R7BF83nbPdk7-5tYkSl5tc'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 95, in _base_aembedding
    return await aembedding(**new_args)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/main.py", line 3894, in aembedding
    raise exception_type(
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/granite/adk_test/adk_venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1267, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: litellm.RateLimitError: geminiException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/embed_content_free_tier_requests",
            "quotaId": "EmbedContentRequestsPerMinutePerUserPerProjectPerModel-FreeTier"
          }
        ]
      }
    ]
  }
}

2025-11-15 16:05:23.0725 - INFO - graphrag.logger.progress - generate embeddings progress: 7/8
2025-11-15 16:05:23.0893 - INFO - graphrag.logger.progress - generate embeddings progress: 8/8
2025-11-15 16:05:24.0164 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
2025-11-15 16:05:24.0165 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/1 of size 500 to vector store
2025-11-15 16:05:24.0175 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 29 inputs via 29 snippets using 3 batches. max_batch_size=16, batch_max_tokens=8191
2025-11-15 16:05:25.0808 - INFO - graphrag.logger.progress - generate embeddings progress: 1/3
2025-11-15 16:05:26.0036 - INFO - graphrag.logger.progress - generate embeddings progress: 2/3
2025-11-15 16:05:26.0262 - INFO - graphrag.logger.progress - generate embeddings progress: 3/3
2025-11-15 16:05:26.0279 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
2025-11-15 16:05:26.0280 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/1 of size 500 to vector store
2025-11-15 16:05:26.0282 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 9 inputs via 9 snippets using 1 batches. max_batch_size=16, batch_max_tokens=8191
2025-11-15 16:05:27.0904 - INFO - graphrag.logger.progress - generate embeddings progress: 1/1
2025-11-15 16:05:27.0916 - INFO - graphrag.index.workflows.generate_text_embeddings - Workflow completed: generate_text_embeddings
2025-11-15 16:05:27.0916 - INFO - graphrag.api.index - Workflow generate_text_embeddings completed successfully
2025-11-15 16:05:27.0934 - INFO - graphrag.index.run.run_pipeline - Indexing pipeline complete.
2025-11-15 16:05:27.0939 - INFO - graphrag.cli.index - All workflows completed successfully.
